<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>阿振的博客</title>
  
  <subtitle>空间信息处理技术分享站</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://theonegis.github.io/"/>
  <updated>2020-04-07T14:12:27.355Z</updated>
  <id>http://theonegis.github.io/</id>
  
  <author>
    <name>阿振</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>手把手教你用QGIS制作地图</title>
    <link href="http://theonegis.github.io/geos/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E7%94%A8QGIS%E5%88%B6%E4%BD%9C%E5%9C%B0%E5%9B%BE/"/>
    <id>http://theonegis.github.io/geos/手把手教你用QGIS制作地图/</id>
    <published>2020-04-07T13:15:44.000Z</published>
    <updated>2020-04-07T14:12:27.355Z</updated>
    
    <content type="html"><![CDATA[<p>版权声明：本文为博主原创文章，转载请注明原文出处！</p><p>写作时间：2020年7月4日晚</p><hr><h1 id="手把手教你使用qgis制作地图">手把手教你使用QGIS制作地图</h1><p>QGIS是一款开源免费的地理信息系统软件，虽然比不上商业的ArcGIS软件，但是QGIS免费而且跨平台，值得学习！</p><p>今天我们聊聊如何使用QGIS进行地图制作并输出。对任意一幅地图的制作下面介绍的步骤并不是都要用得到，我会分知识点进行介绍，学习一些常用地图制作技巧。</p><p>下面我们一步一步进行吧！（我是在macOS平台下进行操作的，Windows平台界面可能稍有差异）</p><h2 id="加载矢量数据">加载矢量数据</h2><p>打开QGIS，从文件管理面板Browser加载所要的数据，如下图所示（以陕西省为例）。</p><figure><img src="/images/geos/making-a-map/屏幕快照%202020-04-07%20下午8.56.03.png" alt=""><figcaption>屏幕快照 2020-04-07 下午8.56.03</figcaption></figure><h2 id="加载背景底图">加载背景底图</h2><p>底图的加载我们可以有很多选择，比如使用OpenStreetMap或者谷歌地图。当然，我们也可以选择不使用底图。</p><p>下面给出加载底图的步骤：</p><p>在文件管理面板Browser的XYZ Tiles节点上右键，选择New Connection…，然后在弹出的对话框中输出Name和URL。下图给出了OpenStreetMap的添加界面。</p><figure><img src="/images/geos/making-a-map/屏幕快照%202020-04-07%20下午8.56.24.png" alt=""><figcaption>屏幕快照 2020-04-07 下午8.56.24</figcaption></figure><p>添加完Connection以后，直接点击添加的地图服务节点将底图添加到我们的工程。</p><p>鼠标在图层Layers面板中拖动数据层的顺序，将刚添加的底图移动到最下方的位置。如下图所示。</p><figure><img src="/images/geos/making-a-map/屏幕快照%202020-04-07%20下午8.56.41.png" alt=""><figcaption>屏幕快照 2020-04-07 下午8.56.41</figcaption></figure><p>此外，这里附上谷歌地图服务的地址，方便有需要的朋友使用：</p><p><strong>Google Maps</strong>: https://mt1.google.com/vt/lyrs=r&amp;x={x}&amp;y={y}&amp;z={z}</p><p><strong>Google Satellite:</strong> http://www.google.cn/maps/vt?lyrs=s@189&amp;gl=cn&amp;x={x}&amp;y={y}&amp;z={z}</p><p><strong>Google Satellite Hybrid:</strong> https://mt1.google.com/vt/lyrs=y&amp;x={x}&amp;y={y}&amp;z={z}</p><p><strong>Google Terrain:</strong> https://mt1.google.com/vt/lyrs=p&amp;x={x}&amp;y={y}&amp;z={z}</p><p><strong>Google Roads:</strong> https://mt1.google.com/vt/lyrs=h&amp;x={x}&amp;y={y}&amp;z={z}</p><p>拿走不谢！</p><h2 id="美化矢量数据">美化矢量数据</h2><p>在Layers面板中选中数据层，右键选择Properties…，在弹出的对话框中选择左侧列表中的Symbology，然后设置矢量数据的填充（Fill），边线（Stroke）等。</p><figure><img src="/images/geos/making-a-map/屏幕快照%202020-04-07%20下午9.43.53.png" alt=""><figcaption>屏幕快照 2020-04-07 下午9.43.53</figcaption></figure><h2 id="添加晕线">添加晕线</h2><p>地图制作中有时候需要给行政边界添加晕线，制作方法很简单。思路是这样的：首先，给原始行政区做缓冲区，然后添加缓冲区到原始行政区图层下面，设置缓冲区的边线的颜色粗细。</p><p>注意：我在使用QGIS的过程中，通过菜单栏Vector-&gt;Geoprocessing Tools-&gt;Buffer…工具进行缓冲区制作的时候，发现制作的缓冲区地理坐标不对（和原始的行政区地理间隔很大），我也不找到出错的原因。</p><p>我通过菜单栏Processing-&gt;Toolbox打开QGIS工具箱，使用GDAL提供的Buffer工具，则不会出现错误，如下图（QGIS中集成了GDAL，GRASS等开源GIS工具，所以经常在处理一个任务的时候，我们有多个工具可以选择）。</p><figure><img src="/images/geos/making-a-map/屏幕快照%202020-04-07%20下午9.00.53.png" alt=""><figcaption>屏幕快照 2020-04-07 下午9.00.53</figcaption></figure><p>做完缓冲区之后，我们需要对缓冲区进行美化（你自己认为漂亮即可），效果如下图！</p><figure><img src="/images/geos/making-a-map/屏幕快照%202020-04-07%20下午9.02.43.png" alt=""><figcaption>屏幕快照 2020-04-07 下午9.02.43</figcaption></figure><h2 id="切换到排版视图">切换到排版视图</h2><p>在ArcGIS中我们一般在进行地图输出的时候一般会切换到布局视图（好像是叫Layotu View，如果我没记错的话）进行地图整饰和出图。</p><p>在QGIS中也是类似的，我们需要点击工具栏的New Print Layout（我的在保存Save Project按钮旁边，我的节目自己调整过，所以可能和标准界面不一样）。这时候会出现一个新的Tab面板（对应ArcGIS的布局视图），我们在该选项卡面板中进行操作，如下图所示。</p><figure><img src="/images/geos/making-a-map/屏幕快照%202020-04-07%20下午9.59.15.png" alt=""><figcaption>屏幕快照 2020-04-07 下午9.59.15</figcaption></figure><p>在布局视图面板的左侧有一系列工具，我们首先点击Add Map按钮，在空白画布上拖动一个地图范围，这样我们刚才制作的地图就会显示在该画布上面。</p><figure><img src="/images/geos/making-a-map/屏幕快照%202020-04-07%20下午9.04.17.png" alt=""><figcaption>屏幕快照 2020-04-07 下午9.04.17</figcaption></figure><h2 id="添加经纬度格网">添加经纬度格网</h2><p>下面我们添加经纬度格网，在该视图的右边Items选项卡中选择我们的地图对象，然后在Item Properties选项卡中，选择Grids节点进行展开，点击➕按钮添加一个Grid对象，然后点击Modify Grid按钮编辑格网的属性。</p><p>我们可以设置格网显示的坐标系，格网显示的间隔，格网显示的样式等等。根据自己的需求自由发挥吧！</p><figure><img src="/images/geos/making-a-map/屏幕快照%202020-04-07%20下午9.04.38.png" alt=""><figcaption>屏幕快照 2020-04-07 下午9.04.38</figcaption></figure><h2 id="添加其他修饰元素">添加其他修饰元素</h2><p>此外，我们还可以点击面板右边的按钮添加比例尺、图例、图名、指北针等等修饰元素。这里不做详细介绍，自己慢慢探索吧！添加完以后，如下图。</p><figure><img src="/images/geos/making-a-map/屏幕快照%202020-04-07%20下午9.14.00.png" alt=""><figcaption>屏幕快照 2020-04-07 下午9.14.00</figcaption></figure><h2 id="地图输出">地图输出</h2><p>最后我们要将地图输出为PDF或者图片格式进行保存，在工具栏提供了相应的按钮进行操作。</p><p>我这里想说的是在QGIS地图制作过程中如果添加了地图服务（Web-Service-Based Map），则有可能在输出保存的时候，底图的显示不太对（会有缩放），我们的矢量地图不存在问题。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;版权声明：本文为博主原创文章，转载请注明原文出处！&lt;/p&gt;
&lt;p&gt;写作时间：2020年7月4日晚&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&quot;手把手教你使用qgis制作地图&quot;&gt;手把手教你使用QGIS制作地图&lt;/h1&gt;
&lt;p&gt;QGIS是一款开源免费的地理信息系统软件，虽然比不上商业的A
      
    
    </summary>
    
      <category term="空间数据处理" scheme="http://theonegis.github.io/categories/geos/"/>
    
    
      <category term="QGIS" scheme="http://theonegis.github.io/tags/QGIS/"/>
    
      <category term="地图制作" scheme="http://theonegis.github.io/tags/%E5%9C%B0%E5%9B%BE%E5%88%B6%E4%BD%9C/"/>
    
      <category term="地图输出" scheme="http://theonegis.github.io/tags/%E5%9C%B0%E5%9B%BE%E8%BE%93%E5%87%BA/"/>
    
  </entry>
  
  <entry>
    <title>从傅立叶级数到傅立叶变化</title>
    <link href="http://theonegis.github.io/math/%E4%BB%8E%E5%82%85%E7%AB%8B%E5%8F%B6%E7%BA%A7%E6%95%B0%E5%88%B0%E5%82%85%E7%AB%8B%E5%8F%B6%E5%8F%98%E5%8C%96/"/>
    <id>http://theonegis.github.io/math/从傅立叶级数到傅立叶变化/</id>
    <published>2019-10-31T11:09:32.000Z</published>
    <updated>2019-10-31T12:29:06.727Z</updated>
    
    <content type="html"><![CDATA[<p>版权声明：本文为博主原创文章，转载请注明原文出处！</p><p>写作时间：2019-10-31</p><hr><p>写这篇博文的初衷是在翻阅数字图像处理相关教科书的时候，发现大部分对傅立叶变换的讲解直接给出了变换公式，而对于公式从何而来并没有给出说明。所以，本文在假设已经了解傅立叶级数的背景下，从傅立叶级数推导出傅立叶变换的一般公式。</p><h1 id="傅立叶级数">傅立叶级数</h1><p>学过高数的童鞋都听过傅立叶级数，下面直接给出定义，具体证明可以参考高等数学教材。</p><p>设周期为<span class="math inline">\(T\)</span>的周期函数<span class="math inline">\(f(x)\)</span>的傅立叶级数为</p><p><span class="math display">\[f(x) = \frac{a_{0}}{2}+\sum_{n=1}^{\infty}\left(a_{n} \cos \frac{2\pi n x}{T}+b_{n} \sin \frac{2\pi n x}{T}\right) \tag{1}\]</span></p><p>其中，系数<span class="math inline">\(a_n\)</span>和<span class="math inline">\(b_n\)</span>分别为：</p><p><span class="math display">\[\left.\begin{array}{ll}{a_{n}=\frac{2}{T} \int_{\frac{T}{2}}^{\frac{T}{2}} f(x) \cos \frac{2\pi n x}{T} \mathrm{d} x} &amp; {(n=0,1,2, \cdots)} \\ {b_{n}=\frac{2}{T} \int_{-\frac{T}{2}}^{\frac{T}{2}} f(x) \sin \frac{2\pi n x}{T} \mathrm{d} x} &amp; {(n=1,2,3, \cdots)}\end{array}\right\} \tag{2}\]</span></p><p>利用欧拉公式<span class="math display">\[\cos t=\frac{\mathrm{e}^{t \mathrm{i}}+\mathrm{e}^{-t i}}{2}, \quad \sin t=\frac{\mathrm{e}^{t i}-\mathrm{e}^{-t i}}{2 \mathrm{i}}\]</span></p><p>可以将公式（1）转化为傅立叶级数的复数形式</p><p><span class="math display">\[f(x) = \sum\limits_{n=-\infty}^{\infty} c_{n} e^{\frac{2\pi n x}{T} \mathrm{i}} \tag{3}\]</span></p><p>系数<span class="math inline">\(c_n\)</span>为</p><p><span class="math display">\[c_{n}=\frac{1}{T} \int_{-\frac{T}{2}}^{\frac{T}{2}} f(x) \mathrm{e}^{-\frac{2\pi n x}{T} \mathrm{i}} \mathrm{d} x \quad(n=0, \pm 1, \pm 2, \cdots) \tag{4}\]</span></p><p>傅立叶级数的两种形式本质上是一样的，但是复数形式比较简洁，而且只用一个算式计算系数。</p><h1 id="傅立叶变换">傅立叶变换</h1><p>傅立叶级数是针对周期函数的，为了可以处理非周期函数，需要傅立叶变换。</p><p>傅立叶变换将周期函数在一个周期内的部分无限延拓，即让周期趋紧于无穷，然后就得到了傅立叶变换，如下图所示。</p><figure><img src="/images/math/FourierTransform.jpeg" alt=""><figcaption>非周期函数延拓</figcaption></figure><p>图片来源：<a href="https://medium.com/sho-jp/fourier-transform-101-part-3-fourier-transform-6def0bd2ca9b" target="_blank" rel="noopener">Fourier Transform 101 — Part 3: Fourier Transform</a></p><p>下面我们看一下，当周期<span class="math inline">\(T\)</span>趋于<span class="math inline">\(\infty\)</span>的时候，我们看一下公式（3）和（4）的变化。</p><p>令<span class="math inline">\(\frac{1}{T} = \Delta \omega\)</span>，则</p><p><span class="math display">\[\begin{align}f(x) &amp;= \sum\limits_{n=-\infty}^{\infty} c_{n} e^{\frac{2 \pi n x}{T} \mathrm{i}} \\ &amp;= \sum\limits_{n=-\infty}^{\infty} c_{n} e^{2 \pi n \Delta \omega x \mathrm{i}} \\ &amp;= \sum\limits_{n=-\infty}^{\infty} \frac{1}{T} [\int_{-\frac{T}{2}}^{\frac{T}{2}} f(x) \mathrm{e}^{-2\pi n \Delta \omega x \mathrm{i}} \mathrm{d} x] e^{2 \pi n \Delta \omega x \mathrm{i}} \\ \end{align}\]</span></p><p>当<span class="math inline">\(T \to \infty\)</span>时，<span class="math inline">\(\Delta \omega \to 0\)</span>，<span class="math inline">\(\Delta \omega \to \mathrm{d}\omega\)</span> ，<span class="math inline">\(\mathrm{d}\omega\)</span>和<span class="math inline">\(n \mathrm{d}\omega\)</span>都成为连续的变量，记为<span class="math inline">\(\omega\)</span>。</p><p><span class="math display">\[\begin{align}f(x) &amp;= \lim_{T\to \infty}{\sum\limits_{n=-\infty}^{\infty} \frac{1}{T} [\int_{-\frac{T}{2}}^{\frac{T}{2}} f(x) \mathrm{e}^{-n \pi xl \mathrm{i}} \mathrm{d} x] e^{2 \pi n \Delta \omega x \mathrm{i}}} \\ &amp;= \int_{-\infty}^{\infty}[\int_{-\infty}^{\infty}f(x)e^{-2\pi\omega x \mathrm{i}} \mathrm{d}x]e^{2\pi\omega x \mathrm{i}}\mathrm{d}\omega \\ \end{align}\]</span></p><p>对应于傅立叶级数，傅立叶变换可以表示为</p><p><span class="math display">\[F(\omega) = \int_{-\infty}^{\infty}f(x)e^{-2\pi\omega x \mathrm{i}} \mathrm{d}x \tag{5}\]</span></p><p>而相应地傅立叶逆变换可以表示为</p><p><span class="math display">\[f(x) = \int_{-\infty}^{\infty}F(\omega) e^{2\pi\omega x \mathrm{i}}\mathrm{d}\omega \tag{6}\]</span></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;版权声明：本文为博主原创文章，转载请注明原文出处！&lt;/p&gt;
&lt;p&gt;写作时间：2019-10-31&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;写这篇博文的初衷是在翻阅数字图像处理相关教科书的时候，发现大部分对傅立叶变换的讲解直接给出了变换公式，而对于公式从何而来并没有给出说明。所以，本文在假设
      
    
    </summary>
    
      <category term="数学" scheme="http://theonegis.github.io/categories/math/"/>
    
    
      <category term="傅立叶变换" scheme="http://theonegis.github.io/tags/%E5%82%85%E7%AB%8B%E5%8F%B6%E5%8F%98%E6%8D%A2/"/>
    
      <category term="傅立叶级数" scheme="http://theonegis.github.io/tags/%E5%82%85%E7%AB%8B%E5%8F%B6%E7%BA%A7%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>Morton码</title>
    <link href="http://theonegis.github.io/algorithm/Morton%E7%A0%81/"/>
    <id>http://theonegis.github.io/algorithm/Morton码/</id>
    <published>2019-07-08T09:11:27.000Z</published>
    <updated>2019-10-31T12:31:45.630Z</updated>
    
    <content type="html"><![CDATA[<p>版权声明：本文为博主原创文章，转载请注明原文出处！</p><p>写作时间：2019-07-08 17:11:27</p><hr><h1 id="morton码的计算">Morton码的计算</h1><p>Morton码是对栅格格网进行编码的一种算法，在Google中搜索Morton，搜索结果第一位是Wikipedia的Z-order Curve，这是因为Morton码编码结果展现为一种Z形的填充曲线。下面简要说一下如何计算四进制和十进制的Morton码。</p><figure><img src="/images/geos/z-curve.png" alt=""><figcaption>Morton码二进制</figcaption></figure><h2 id="四进制morton码计算">四进制Morton码计算</h2><p>四进制编码对左上，右上，左下，右下的顺序对四个格网单元分布编码为0，1，2，3。</p><p>其计算方式为：二进制的行列号<span class="math inline">\(r\)</span>、<span class="math inline">\(l\)</span>（从第0行0列开始），四进制编码<span class="math inline">\(M=2*l+ r\)</span>；那么这里就是：第5行（101）第7列（111）：<span class="math inline">\(M=2*101+111=313\)</span>（313对应的十进制是55）</p><h2 id="十进制morton码计算">十进制Morton码计算</h2><p>十进制的编码规则：首先，行列号转为二进制（从第0行0列开始）；然后行列号交叉排列；最后将二进制结果转为十进制。十进制Morton编码是按左上，右上，左下，右下的顺序从0开始对每个格网进行自然编码的。</p><p>对于第5行（101）第7列（111），交叉排列得到110111，然后转为十进制就是55。和四进制的编码结果是一样的。</p><p>下面给出十进制Morton码的C++实现：</p><div class="sourceCode" id="cb1"><pre class="sourceCode c++"><code class="sourceCode cpp"><span id="cb1-1"><a href="#cb1-1"></a><span class="pp">#include </span><span class="im">&lt;iostream&gt;</span></span><span id="cb1-2"><a href="#cb1-2"></a></span><span id="cb1-3"><a href="#cb1-3"></a><span class="kw">using</span> <span class="bu">std::</span>cout;</span><span id="cb1-4"><a href="#cb1-4"></a></span><span id="cb1-5"><a href="#cb1-5"></a><span class="dt">int</span> main() {</span><span id="cb1-6"><a href="#cb1-6"></a>    <span class="dt">uint32_t</span> row = <span class="dv">5</span>;</span><span id="cb1-7"><a href="#cb1-7"></a>    <span class="dt">uint32_t</span> col = <span class="dv">7</span>;</span><span id="cb1-8"><a href="#cb1-8"></a>    <span class="dt">uint64_t</span> morton = <span class="dv">0</span>;</span><span id="cb1-9"><a href="#cb1-9"></a></span><span id="cb1-10"><a href="#cb1-10"></a>    <span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; <span class="kw">sizeof</span>(row) * <span class="dv">8</span>; i++) {</span><span id="cb1-11"><a href="#cb1-11"></a>        morton |= (row &amp; (<span class="dt">uint64_t</span>)<span class="dv">1</span> &lt;&lt; i) &lt;&lt; i | (col &amp; (<span class="dt">uint64_t</span>)<span class="dv">1</span> &lt;&lt; i) &lt;&lt; (i + <span class="dv">1</span>);</span><span id="cb1-12"><a href="#cb1-12"></a>    }</span><span id="cb1-13"><a href="#cb1-13"></a>    cout &lt;&lt; morton &lt;&lt; <span class="ch">&#39;</span><span class="sc">\n</span><span class="ch">&#39;</span>;</span><span id="cb1-14"><a href="#cb1-14"></a>    <span class="cf">return</span> <span class="dv">0</span>;</span><span id="cb1-15"><a href="#cb1-15"></a>}</span></code></pre></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;版权声明：本文为博主原创文章，转载请注明原文出处！&lt;/p&gt;
&lt;p&gt;写作时间：2019-07-08 17:11:27&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&quot;morton码的计算&quot;&gt;Morton码的计算&lt;/h1&gt;
&lt;p&gt;Morton码是对栅格格网进行编码的一种算法，在Google中
      
    
    </summary>
    
      <category term="算法" scheme="http://theonegis.github.io/categories/algorithm/"/>
    
    
      <category term="Morton" scheme="http://theonegis.github.io/tags/Morton/"/>
    
  </entry>
  
  <entry>
    <title>NumPy中的维度Axis</title>
    <link href="http://theonegis.github.io/python/NumPy%E4%B8%AD%E7%9A%84%E7%BB%B4%E5%BA%A6Axis/"/>
    <id>http://theonegis.github.io/python/NumPy中的维度Axis/</id>
    <published>2019-04-16T06:56:53.000Z</published>
    <updated>2019-04-16T19:35:24.935Z</updated>
    
    <content type="html"><![CDATA[<p>版权声明：本文为博主原创文章，转载请注明原文出处！</p><p>写作时间：2019-04-16 14:56:53</p><hr><h1 id="浅谈numpy中的维度axis">浅谈NumPy中的维度Axis</h1><p>NumPy中的维度是一个很重要的概念，很多函数的参数都需要给定维度Axis，如何直观的理解维度呢？我们首先以二维数组为例进行说明，然后推广到多维数组。</p><p>(有人将<code>ndim</code>属性叫维度，将<code>axis</code>叫轴，我还是习惯将<code>axis</code>称之为维度，<code>axis=0</code>称为第一个维度)</p><h2 id="二维数组的列子">二维数组的列子</h2><p>下面是一个二维数组的列子：</p><div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a>In [<span class="dv">1</span>]: <span class="im">import</span> numpy <span class="im">as</span> np</span><span id="cb1-2"><a href="#cb1-2"></a></span><span id="cb1-3"><a href="#cb1-3"></a>In [<span class="dv">2</span>]: x <span class="op">=</span> np.random.randint(<span class="dv">0</span>, <span class="dv">9</span>, (<span class="dv">2</span>, <span class="dv">3</span>))</span><span id="cb1-4"><a href="#cb1-4"></a></span><span id="cb1-5"><a href="#cb1-5"></a>In [<span class="dv">3</span>]: x</span><span id="cb1-6"><a href="#cb1-6"></a>Out[<span class="dv">3</span>]:</span><span id="cb1-7"><a href="#cb1-7"></a>array([[<span class="dv">0</span>, <span class="dv">8</span>, <span class="dv">6</span>],</span><span id="cb1-8"><a href="#cb1-8"></a>       [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>]])</span><span id="cb1-9"><a href="#cb1-9"></a></span><span id="cb1-10"><a href="#cb1-10"></a>In [<span class="dv">4</span>]: x.ndim</span><span id="cb1-11"><a href="#cb1-11"></a>Out[<span class="dv">4</span>]: <span class="dv">2</span></span><span id="cb1-12"><a href="#cb1-12"></a></span><span id="cb1-13"><a href="#cb1-13"></a>In [<span class="dv">5</span>]: x.shape</span><span id="cb1-14"><a href="#cb1-14"></a>Out[<span class="dv">5</span>]: (<span class="dv">2</span>, <span class="dv">3</span>)</span><span id="cb1-15"><a href="#cb1-15"></a></span><span id="cb1-16"><a href="#cb1-16"></a>In [<span class="dv">6</span>]: x[<span class="dv">0</span>]</span><span id="cb1-17"><a href="#cb1-17"></a>Out[<span class="dv">6</span>]: array([<span class="dv">0</span>, <span class="dv">8</span>, <span class="dv">6</span>])</span><span id="cb1-18"><a href="#cb1-18"></a></span><span id="cb1-19"><a href="#cb1-19"></a>In [<span class="dv">7</span>]: x[:, <span class="dv">0</span>]</span><span id="cb1-20"><a href="#cb1-20"></a>Out[<span class="dv">7</span>]: array([<span class="dv">0</span>, <span class="dv">1</span>])</span><span id="cb1-21"><a href="#cb1-21"></a></span><span id="cb1-22"><a href="#cb1-22"></a>In [<span class="dv">8</span>]: x.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>)</span><span id="cb1-23"><a href="#cb1-23"></a>Out[<span class="dv">8</span>]: array([ <span class="dv">1</span>, <span class="dv">10</span>,  <span class="dv">7</span>])</span><span id="cb1-24"><a href="#cb1-24"></a></span><span id="cb1-25"><a href="#cb1-25"></a>In [<span class="dv">9</span>]: x.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)</span><span id="cb1-26"><a href="#cb1-26"></a>Out[<span class="dv">9</span>]: array([<span class="dv">14</span>,  <span class="dv">4</span>])</span><span id="cb1-27"><a href="#cb1-27"></a></span><span id="cb1-28"><a href="#cb1-28"></a>In [<span class="dv">10</span>]: x[<span class="dv">0</span>] <span class="op">+</span> x[<span class="dv">1</span>]</span><span id="cb1-29"><a href="#cb1-29"></a>Out[<span class="dv">10</span>]: array([ <span class="dv">1</span>, <span class="dv">10</span>,  <span class="dv">7</span>])</span><span id="cb1-30"><a href="#cb1-30"></a></span><span id="cb1-31"><a href="#cb1-31"></a>In [<span class="dv">11</span>]: x[:, <span class="dv">0</span>] <span class="op">+</span> x[:, <span class="dv">1</span>] <span class="op">+</span> x[:, <span class="dv">2</span>]</span><span id="cb1-32"><a href="#cb1-32"></a>Out[<span class="dv">11</span>]: array([<span class="dv">14</span>,  <span class="dv">4</span>])</span></code></pre></div><p>看上面这个例子，<code>x</code>是一个2行3列的数组，所以<code>x</code>是一个二维数组。</p><p>从第6和第7个输入输出，我们可以肯定地说“对于二维数组，第一维指的是行，第二维指的是列”。</p><p>我们通过<code>sum</code>求和函数，探究一下<code>x</code>的第一维和第二维的意义？从第8个和第9个输入输出，我们可以看到对于参数<code>axis=0</code>，其结果是数组列的和；而对于参数<code>axis=1</code>，其参数是数组行的和。</p><p>对于<code>axis=0</code>第一个维度求和，不是将第一维度（行）中的所有元素相加，而是沿着第一个维度，将对应其他维度（列）的数据相加，分解开来就是第10个输入输出。同理，对于<code>axis=1</code>，是沿着列，将行中的元素相加。</p><p>NumPy中对于维度的操作都是以类似这样的逻辑操作的。</p><h2 id="多维数组">多维数组</h2><p>对于多维数组我们如何准确区分维度呢？下面以图示进行说明：</p><figure><img src="/images/python/NumPy中的维度.png" alt=""><figcaption>NumPy中的维度</figcaption></figure><p>所以，我的结论就是：在概念上维度是从整体到局部看的，最外围的是第一个维度，然后依次往里，最内部的就是最后一维。</p><p>下面我们用代码验证一下上面的结论：</p><div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a>In [<span class="dv">19</span>]: x <span class="op">=</span> np.random.randint(<span class="dv">0</span>, <span class="dv">9</span>, (<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>))</span><span id="cb2-2"><a href="#cb2-2"></a></span><span id="cb2-3"><a href="#cb2-3"></a>In [<span class="dv">20</span>]: x</span><span id="cb2-4"><a href="#cb2-4"></a>Out[<span class="dv">20</span>]:</span><span id="cb2-5"><a href="#cb2-5"></a>array([[[<span class="dv">0</span>, <span class="dv">7</span>, <span class="dv">5</span>, <span class="dv">5</span>],</span><span id="cb2-6"><a href="#cb2-6"></a>        [<span class="dv">6</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">3</span>],</span><span id="cb2-7"><a href="#cb2-7"></a>        [<span class="dv">7</span>, <span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">4</span>]],</span><span id="cb2-8"><a href="#cb2-8"></a></span><span id="cb2-9"><a href="#cb2-9"></a>       [[<span class="dv">8</span>, <span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">6</span>],</span><span id="cb2-10"><a href="#cb2-10"></a>        [<span class="dv">8</span>, <span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">8</span>],</span><span id="cb2-11"><a href="#cb2-11"></a>        [<span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">8</span>, <span class="dv">2</span>]]])</span><span id="cb2-12"><a href="#cb2-12"></a></span><span id="cb2-13"><a href="#cb2-13"></a>In [<span class="dv">21</span>]: x[<span class="dv">0</span>]</span><span id="cb2-14"><a href="#cb2-14"></a>Out[<span class="dv">21</span>]:</span><span id="cb2-15"><a href="#cb2-15"></a>array([[<span class="dv">0</span>, <span class="dv">7</span>, <span class="dv">5</span>, <span class="dv">5</span>],</span><span id="cb2-16"><a href="#cb2-16"></a>       [<span class="dv">6</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">3</span>],</span><span id="cb2-17"><a href="#cb2-17"></a>       [<span class="dv">7</span>, <span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">4</span>]])</span><span id="cb2-18"><a href="#cb2-18"></a></span><span id="cb2-19"><a href="#cb2-19"></a>In [<span class="dv">22</span>]: x[:, <span class="dv">0</span>, :]</span><span id="cb2-20"><a href="#cb2-20"></a>Out[<span class="dv">22</span>]:</span><span id="cb2-21"><a href="#cb2-21"></a>array([[<span class="dv">0</span>, <span class="dv">7</span>, <span class="dv">5</span>, <span class="dv">5</span>],</span><span id="cb2-22"><a href="#cb2-22"></a>       [<span class="dv">8</span>, <span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">6</span>]])</span></code></pre></div><p>可以看到，第21个输入输出取到的是第一维的第一个元素，第22个输入输出取到的是第二维的第一个元素。大家可以细细体味一下！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;版权声明：本文为博主原创文章，转载请注明原文出处！&lt;/p&gt;
&lt;p&gt;写作时间：2019-04-16 14:56:53&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&quot;浅谈numpy中的维度axis&quot;&gt;浅谈NumPy中的维度Axis&lt;/h1&gt;
&lt;p&gt;NumPy中的维度是一个很重要的概念，很多
      
    
    </summary>
    
      <category term="Python" scheme="http://theonegis.github.io/categories/python/"/>
    
    
      <category term="NumPy" scheme="http://theonegis.github.io/tags/NumPy/"/>
    
  </entry>
  
  <entry>
    <title>栅格数据裁剪</title>
    <link href="http://theonegis.github.io/geos/%E6%A0%85%E6%A0%BC%E6%95%B0%E6%8D%AE%E8%A3%81%E5%89%AA/"/>
    <id>http://theonegis.github.io/geos/栅格数据裁剪/</id>
    <published>2019-03-22T07:35:09.000Z</published>
    <updated>2019-03-22T19:39:16.792Z</updated>
    
    <content type="html"><![CDATA[<p>版权声明：本文为博主原创文章，转载请注明原文出处！ 写作时间：2019-03-22</p><p>在进行遥感影像处理的时候，我们经常需要进行裁剪的工作，来看看如何使用GDAL工具进行这项操作吧！</p><p>参考资料：</p><ol type="1"><li><a href="https://www.gdal.org/gdalwarp.html" target="_blank" rel="noopener">GDAL: gdalwarp</a></li><li><a href="https://www.gdal.org/gdal_translate.html" target="_blank" rel="noopener">GDAL: gdal_translate</a></li><li><a href="https://gdal.org/python/" target="_blank" rel="noopener">GDAL/OGR Python API</a></li></ol><h2 id="使用gdal命令">使用GDAL命令</h2><p>GDAL提供了两个命令可以用于影像的裁剪：<code>gdalwarp</code>和<code>gdal_translate</code>，两个命令中我更推荐使用后者。</p><p><code>gdalwarp</code>命令可以使用<code>-te</code>制定裁剪范围。默认是在原数据的坐标系下的<code>xmin ymin xmax ymax</code>，当然我们也可以使用<code>-te_srs</code>参数指定<code>-te</code>参数所在的坐标系。</p><p>为什么不推荐<code>gdalwarp</code>命令呢？这是因为<code>gdalwarp</code>命令只提供了根据坐标系的范围进行裁剪，而不支持根据行列号的裁剪。这时候我们可以求助于<code>gdal_translate</code>命令。</p><p><code>gdal_transalte</code>命令即支持使用<code>-srcwin</code>参数指定行列号范围<code>xoff yoff xsize ysize</code>，也支持使用<code>-projwin</code>参数指定原数据坐标系下的范围<code>ulx uly lrx lry</code>。同时提供参数<code>-projwin_srs</code>可以用于指定<code>-projwin</code>参数所在的坐标系，即跟<code>gdalwarp</code>命令中的<code>-te_srs</code>参数类似。</p><p>下面给出一个示例：</p><p><code>gdal_translate -of "GTiff" -srcwin 10 10 256 256 -a_scale 1 HDF4_EOS:EOS_GRID:"MOD09GA.A2018349.h26v05.006.2018351030314.hdf":MODIS_Grid_500m_2D:sur_refl_b01_1 sr_1.tif</code></p><p>这行命令将MODIS数据中的反射率的第一波段进行裁剪，起点为第10行第10列，输出大小为256$$255，输出格式为TIFF。</p><p>注意这行命令有一个<code>-a_scale 1</code>参数，这个参数指定了裁剪过程不要对DN值进行缩放。如果不加这个值得话，输出图像的DN值会被根据原数据的<code>Scale=10000</code>放大10000倍。</p><h2 id="使用python代码">使用Python代码</h2><p>对于使用Python代码进行裁剪，我们有两种方法：</p><ul><li>第一就是对命令行对应的借口直接进行调用。这个最直接最简单。</li><li>第二就是首先自己选择出需要裁剪的区域，然后计算裁剪区域的GeoTransform的系数，最后将投影和GeoTransform系数赋值给裁剪子区域，写入输出文件。</li></ul><p>我们知道<a href="https://blog.csdn.net/theonegis/article/details/80304873" target="_blank" rel="noopener">GDAL中使用了六参数模型存储GeoTransform参数</a>，如果进行矩形裁剪的话，只有<code>GT(0)</code>和<code>GT(3)</code>参数会有变化，即需要重新计算裁剪以后的左上角坐标即可。</p><p>下面给出使用Python对MODIS反射率的第一波段进行裁剪的代码：</p><div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">from</span> osgeo <span class="im">import</span> gdal</span><span id="cb1-2"><a href="#cb1-2"></a><span class="im">import</span> numpy <span class="im">as</span> np</span><span id="cb1-3"><a href="#cb1-3"></a></span><span id="cb1-4"><a href="#cb1-4"></a><span class="co"># API参考：https://gdal.org/python/</span></span><span id="cb1-5"><a href="#cb1-5"></a><span class="co"># GDAL命令行参考：https://www.gdal.org/gdal_translate.html</span></span><span id="cb1-6"><a href="#cb1-6"></a>image_name <span class="op">=</span> (<span class="st">&#39;HDF4_EOS:EOS_GRID:&#39;</span></span><span id="cb1-7"><a href="#cb1-7"></a>              <span class="st">&#39;&quot;MOD09GA.A2018349.h26v05.006.2018351030314.hdf&quot;:&#39;</span></span><span id="cb1-8"><a href="#cb1-8"></a>              <span class="st">&#39;MODIS_Grid_500m_2D:sur_refl_b01_1&#39;</span>)</span><span id="cb1-9"><a href="#cb1-9"></a></span><span id="cb1-10"><a href="#cb1-10"></a><span class="co"># 第一种方式，也是最简单的方法：直接使用GDAL命令行对应的Python方法</span></span><span id="cb1-11"><a href="#cb1-11"></a>src: gdal.Dataset <span class="op">=</span> gdal.Open(image_name)</span><span id="cb1-12"><a href="#cb1-12"></a>src <span class="op">=</span> gdal.Translate(<span class="st">&#39;cropped_with_translate.tif&#39;</span>, src, srcWin<span class="op">=</span>[<span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">256</span>, <span class="dv">256</span>],</span><span id="cb1-13"><a href="#cb1-13"></a>                     options<span class="op">=</span>[<span class="st">&#39;-a_scale&#39;</span>, <span class="st">&#39;1&#39;</span>])</span><span id="cb1-14"><a href="#cb1-14"></a><span class="kw">del</span> src</span><span id="cb1-15"><a href="#cb1-15"></a></span><span id="cb1-16"><a href="#cb1-16"></a><span class="co"># 第二种方式，自己选择出需要的像素，然后自己确定裁剪以后的空间参考关系，并写入到输出文件</span></span><span id="cb1-17"><a href="#cb1-17"></a>src: gdal.Dataset <span class="op">=</span> gdal.Open(image_name)</span><span id="cb1-18"><a href="#cb1-18"></a>band: gdal.Band <span class="op">=</span> src.GetRasterBand(<span class="dv">1</span>)</span><span id="cb1-19"><a href="#cb1-19"></a>subset: np.ndarray <span class="op">=</span> band.ReadAsArray(<span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">256</span>, <span class="dv">256</span>)</span><span id="cb1-20"><a href="#cb1-20"></a></span><span id="cb1-21"><a href="#cb1-21"></a>driver: gdal.Driver <span class="op">=</span> gdal.GetDriverByName(<span class="st">&#39;GTiff&#39;</span>)</span><span id="cb1-22"><a href="#cb1-22"></a>dst: gdal.Dataset <span class="op">=</span> driver.Create(<span class="st">&#39;cropped_from_scratch.tif&#39;</span>, <span class="dv">256</span>, <span class="dv">256</span>, <span class="dv">1</span>, gdal.GDT_Int16)</span><span id="cb1-23"><a href="#cb1-23"></a>dst.SetProjection(src.GetProjection())</span><span id="cb1-24"><a href="#cb1-24"></a>trans <span class="op">=</span> <span class="bu">list</span>(src.GetGeoTransform())</span><span id="cb1-25"><a href="#cb1-25"></a>trans[<span class="dv">0</span>] <span class="op">-=</span> <span class="op">-</span><span class="dv">10</span> <span class="op">*</span> trans[<span class="dv">1</span>]</span><span id="cb1-26"><a href="#cb1-26"></a>trans[<span class="dv">3</span>] <span class="op">-=</span> <span class="op">-</span><span class="dv">10</span> <span class="op">*</span> trans[<span class="dv">5</span>]</span><span id="cb1-27"><a href="#cb1-27"></a>dst.SetGeoTransform(<span class="bu">tuple</span>(trans))</span><span id="cb1-28"><a href="#cb1-28"></a></span><span id="cb1-29"><a href="#cb1-29"></a>band: gdal.Band <span class="op">=</span> dst.GetRasterBand(<span class="dv">1</span>)</span><span id="cb1-30"><a href="#cb1-30"></a>band.WriteArray(subset)</span><span id="cb1-31"><a href="#cb1-31"></a>band.FlushCache()</span><span id="cb1-32"><a href="#cb1-32"></a><span class="kw">del</span> src</span><span id="cb1-33"><a href="#cb1-33"></a><span class="kw">del</span> dst</span></code></pre></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;版权声明：本文为博主原创文章，转载请注明原文出处！ 写作时间：2019-03-22&lt;/p&gt;
&lt;p&gt;在进行遥感影像处理的时候，我们经常需要进行裁剪的工作，来看看如何使用GDAL工具进行这项操作吧！&lt;/p&gt;
&lt;p&gt;参考资料：&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;a h
      
    
    </summary>
    
      <category term="空间数据处理" scheme="http://theonegis.github.io/categories/geos/"/>
    
    
      <category term="Python" scheme="http://theonegis.github.io/tags/Python/"/>
    
      <category term="GDAL" scheme="http://theonegis.github.io/tags/GDAL/"/>
    
      <category term="裁剪" scheme="http://theonegis.github.io/tags/%E8%A3%81%E5%89%AA/"/>
    
  </entry>
  
  <entry>
    <title>Python中如何优雅地使用switch语句</title>
    <link href="http://theonegis.github.io/python/Python%E4%B8%AD%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%9C%B0%E4%BD%BF%E7%94%A8switch%E8%AF%AD%E5%8F%A5/"/>
    <id>http://theonegis.github.io/python/Python中如何优雅地使用switch语句/</id>
    <published>2019-03-07T05:49:45.000Z</published>
    <updated>2019-03-22T19:39:53.825Z</updated>
    
    <content type="html"><![CDATA[<p>版权声明：本文为博主原创文章，转载请注明原文出处！</p><p>写作时间：2019-03-07 13:49:45</p><h1 id="python中如何优雅地使用switch语句">Python中如何优雅地使用switch语句</h1><p>我们知道Python中没有类似C++或者Java中的<code>switch...case</code>语句，我们可以使用多个<code>if...elif...else</code>进行模拟，但是这样的写法让代码看起来很凌乱，个人不是很推荐在代码中大量使用<code>if</code>语句。</p><p>那么解决的办法是什么呢？答曰：字典（<code>dict</code>）。下面我们以两个典型案例进行说明。</p><h2 id="案例一简单情况">案例一（简单情况）</h2><p>第一种简单情况就是一对一，给定一个值，返回一个值，这是C++和Java中的<code>switch</code>语句支持的情况。</p><p>下面的案例是将英文日期翻译为中文日期：</p><div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a>dates <span class="op">=</span> {</span><span id="cb1-2"><a href="#cb1-2"></a>    <span class="st">&#39;Sun&#39;</span>: <span class="st">&#39;星期天&#39;</span>, <span class="st">&#39;Mon&#39;</span>: <span class="st">&#39;星期一&#39;</span>, <span class="st">&#39;Tues&#39;</span>: <span class="st">&#39;星期二&#39;</span>, <span class="st">&#39;Wed&#39;</span>: <span class="st">&#39;星期三&#39;</span>,</span><span id="cb1-3"><a href="#cb1-3"></a>    <span class="st">&#39;Thurs&#39;</span>: <span class="st">&#39;星期四&#39;</span>, <span class="st">&#39;Fri&#39;</span>: <span class="st">&#39;星期五&#39;</span>, <span class="st">&#39;Sat&#39;</span>: <span class="st">&#39;星期六&#39;</span>}</span><span id="cb1-4"><a href="#cb1-4"></a></span><span id="cb1-5"><a href="#cb1-5"></a>day <span class="op">=</span> dates.get(<span class="st">&#39;Fri&#39;</span>, <span class="st">&#39;未知&#39;</span>)</span><span id="cb1-6"><a href="#cb1-6"></a><span class="bu">print</span>(day)  <span class="co"># 输出结果为星期五</span></span></code></pre></div><h2 id="案例二带条件判断">案例二（带条件判断）</h2><p>第二种情况是多对一，反映在编程上就是<code>case</code>语句中带条件判断，这个是诸如Scala中的<code>switch</code>和Kotlin中的<code>when</code>支持的情况。</p><p>下面给出的案例是给定一个数字，如果该数字在某个范围之类，则返回一个指定的数字。</p><div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="co"># 这里的conditions是一个函数</span></span><span id="cb2-2"><a href="#cb2-2"></a>conditions <span class="op">=</span> <span class="kw">lambda</span> x: {</span><span id="cb2-3"><a href="#cb2-3"></a>    x <span class="op">&lt;</span> <span class="op">-</span><span class="dv">1</span>: <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span> <span class="op">&lt;=</span> x <span class="op">&lt;=</span> <span class="dv">1</span>: <span class="fl">0.5</span>, x <span class="op">&gt;</span> <span class="dv">1</span>: <span class="dv">1</span></span><span id="cb2-4"><a href="#cb2-4"></a>}</span><span id="cb2-5"><a href="#cb2-5"></a></span><span id="cb2-6"><a href="#cb2-6"></a>num <span class="op">=</span> conditions(<span class="fl">0.25</span>)[<span class="va">True</span>]</span><span id="cb2-7"><a href="#cb2-7"></a><span class="bu">print</span>(num)</span><span id="cb2-8"><a href="#cb2-8"></a>num <span class="op">=</span> conditions(<span class="dv">10</span>)[<span class="va">True</span>]</span><span id="cb2-9"><a href="#cb2-9"></a><span class="bu">print</span>(num)</span></code></pre></div><p>这里我们的<code>dict</code>不是一个普通的字典，其<code>key</code>是一个<code>lambda</code>表达式（一个函数）。如果我们调用该函数，则会返回一个字典，该字典中有两个元素：一个元素的键是<code>True</code>，另一个是<code>False</code>。<code>True</code>元素包含的值是对应<code>lambda</code>函数中满足条件的给定值，<code>False</code>元素包含的值是对应<code>lambda</code>函数中最后一个不满足条件的给定值（这句话写得比较拗口，不好理解。动手实践一下，可以加深理解）。</p><p>经过上面的介绍，我们以后可以大大减少对<code>if...else</code>语句的使用了，让我们的代码更加干净一些！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;版权声明：本文为博主原创文章，转载请注明原文出处！&lt;/p&gt;
&lt;p&gt;写作时间：2019-03-07 13:49:45&lt;/p&gt;
&lt;h1 id=&quot;python中如何优雅地使用switch语句&quot;&gt;Python中如何优雅地使用switch语句&lt;/h1&gt;
&lt;p&gt;我们知道Python中没
      
    
    </summary>
    
      <category term="Python" scheme="http://theonegis.github.io/categories/python/"/>
    
    
      <category term="Python" scheme="http://theonegis.github.io/tags/Python/"/>
    
      <category term="Switch" scheme="http://theonegis.github.io/tags/Switch/"/>
    
  </entry>
  
  <entry>
    <title>使用卷积网络做手写数字识别</title>
    <link href="http://theonegis.github.io/dl/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E5%81%9A%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/"/>
    <id>http://theonegis.github.io/dl/使用卷积网络做手写数字识别/</id>
    <published>2019-03-02T14:24:22.000Z</published>
    <updated>2019-03-22T19:39:53.829Z</updated>
    
    <content type="html"><![CDATA[<p>版权声明：本文为博主原创文章，转载请注明原文出处！</p><p>写作时间：2019-03-02 22:24:22</p><h1 id="使用卷积网络做手写数字识别">使用卷积网络做手写数字识别</h1><h2 id="思路分析">思路分析</h2><p>上篇博文《<a href="https://theonegis.blog.csdn.net/article/details/88086423" target="_blank" rel="noopener">使用循环神经网络做手写数字识别</a>》介绍了利用LSTM做手写数字的识别，想着好事成双，也写一个姊妹篇卷积网络实现手写数字的识别。</p><p>博文主要通过最简单的代码量展示一个入门级别的识别案例。需要注意的几点：</p><ul><li>卷积网络的输入大小为（<code>batch_size</code>，<code>num_channels</code>，<code>image_width</code>，<code>image_height</code>）</li><li>本文中的模型使用了卷积层和线性连接层。Linear层的输入大小为（<code>*</code>，<code>num_input_feature</code>），所以在卷积层输出流入线性层的时候，需要转化一下张量的尺寸大小</li><li>综合使用<code>MaxPooling</code>层和<code>Dropout</code>层可以提高识别准确率</li></ul><h2 id="pytorch实现">PyTorch实现</h2><div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> torch</span><span id="cb1-2"><a href="#cb1-2"></a><span class="im">from</span> torch <span class="im">import</span> nn</span><span id="cb1-3"><a href="#cb1-3"></a><span class="im">import</span> torchvision.datasets <span class="im">as</span> datasets</span><span id="cb1-4"><a href="#cb1-4"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span><span id="cb1-5"><a href="#cb1-5"></a></span><span id="cb1-6"><a href="#cb1-6"></a>torch.manual_seed(<span class="dv">2019</span>)</span><span id="cb1-7"><a href="#cb1-7"></a></span><span id="cb1-8"><a href="#cb1-8"></a><span class="co"># 超参设置</span></span><span id="cb1-9"><a href="#cb1-9"></a>EPOCH <span class="op">=</span> <span class="dv">1</span>  <span class="co"># 训练EPOCH次，这里为了测试方便只跑一次</span></span><span id="cb1-10"><a href="#cb1-10"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">32</span></span><span id="cb1-11"><a href="#cb1-11"></a>INIT_LR <span class="op">=</span> <span class="fl">1e-3</span>  <span class="co"># 初始学习率</span></span><span id="cb1-12"><a href="#cb1-12"></a>DOWNLOAD_MNIST <span class="op">=</span> <span class="va">True</span>  <span class="co"># 设置是否需要下载数据集</span></span><span id="cb1-13"><a href="#cb1-13"></a></span><span id="cb1-14"><a href="#cb1-14"></a><span class="co"># 使用DataLoader加载训练数据，为了演示方便，对于测试数据只取出2000个样本进行测试</span></span><span id="cb1-15"><a href="#cb1-15"></a>train_data <span class="op">=</span> datasets.MNIST(root<span class="op">=</span><span class="st">&#39;mnist&#39;</span>, train<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transforms.ToTensor(), download<span class="op">=</span>DOWNLOAD_MNIST)</span><span id="cb1-16"><a href="#cb1-16"></a>train_loader <span class="op">=</span> torch.utils.data.DataLoader(dataset<span class="op">=</span>train_data, batch_size<span class="op">=</span>BATCH_SIZE, shuffle<span class="op">=</span><span class="va">True</span>)</span><span id="cb1-17"><a href="#cb1-17"></a>test_data <span class="op">=</span> datasets.MNIST(root<span class="op">=</span><span class="st">&#39;mnist&#39;</span>, train<span class="op">=</span><span class="va">False</span>)</span><span id="cb1-18"><a href="#cb1-18"></a>test_x <span class="op">=</span> test_data.test_data.<span class="bu">type</span>(torch.FloatTensor)[:<span class="dv">2000</span>] <span class="op">/</span> <span class="fl">255.</span></span><span id="cb1-19"><a href="#cb1-19"></a>test_x.unsqueeze_(<span class="dv">1</span>)  <span class="co"># 调整test_x的尺寸为四维，添加了一个channel维度</span></span><span id="cb1-20"><a href="#cb1-20"></a>test_y <span class="op">=</span> test_data.test_labels.numpy()[:<span class="dv">2000</span>]</span><span id="cb1-21"><a href="#cb1-21"></a></span><span id="cb1-22"><a href="#cb1-22"></a></span><span id="cb1-23"><a href="#cb1-23"></a><span class="kw">class</span> ConvNet(nn.Module):</span><span id="cb1-24"><a href="#cb1-24"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span><span id="cb1-25"><a href="#cb1-25"></a>        <span class="bu">super</span>(ConvNet, <span class="va">self</span>).<span class="fu">__init__</span>()</span><span id="cb1-26"><a href="#cb1-26"></a>        <span class="va">self</span>.conv <span class="op">=</span> nn.Sequential(</span><span id="cb1-27"><a href="#cb1-27"></a>            nn.Conv2d(<span class="dv">1</span>, <span class="dv">32</span>, <span class="dv">5</span>),  <span class="co"># 图像输出大小为24*24</span></span><span id="cb1-28"><a href="#cb1-28"></a>            nn.MaxPool2d(<span class="dv">2</span>),  <span class="co"># 图像输出大小为12*12</span></span><span id="cb1-29"><a href="#cb1-29"></a>            nn.ReLU(<span class="va">True</span>),</span><span id="cb1-30"><a href="#cb1-30"></a>            nn.Conv2d(<span class="dv">32</span>, <span class="dv">64</span>, <span class="dv">5</span>),  <span class="co"># 图像输出大小为8*8</span></span><span id="cb1-31"><a href="#cb1-31"></a>            nn.Dropout2d(),</span><span id="cb1-32"><a href="#cb1-32"></a>            nn.MaxPool2d(<span class="dv">2</span>),  <span class="co"># 图像输出大小为4*4</span></span><span id="cb1-33"><a href="#cb1-33"></a>            nn.ReLU(<span class="va">True</span>)</span><span id="cb1-34"><a href="#cb1-34"></a>        )</span><span id="cb1-35"><a href="#cb1-35"></a></span><span id="cb1-36"><a href="#cb1-36"></a>        <span class="va">self</span>.linear <span class="op">=</span> nn.Sequential(</span><span id="cb1-37"><a href="#cb1-37"></a>            nn.Linear(<span class="dv">4</span> <span class="op">*</span> <span class="dv">4</span> <span class="op">*</span> <span class="dv">64</span>, <span class="dv">128</span>),</span><span id="cb1-38"><a href="#cb1-38"></a>            nn.ReLU(<span class="va">True</span>),</span><span id="cb1-39"><a href="#cb1-39"></a>            nn.Dropout2d(),</span><span id="cb1-40"><a href="#cb1-40"></a>            nn.Linear(<span class="dv">128</span>, <span class="dv">10</span>),</span><span id="cb1-41"><a href="#cb1-41"></a>            nn.Softmax(<span class="dv">1</span>)</span><span id="cb1-42"><a href="#cb1-42"></a>        )</span><span id="cb1-43"><a href="#cb1-43"></a></span><span id="cb1-44"><a href="#cb1-44"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span><span id="cb1-45"><a href="#cb1-45"></a>        x <span class="op">=</span> <span class="va">self</span>.conv(x)</span><span id="cb1-46"><a href="#cb1-46"></a>        x <span class="op">=</span> x.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span> <span class="op">*</span> <span class="dv">4</span> <span class="op">*</span> <span class="dv">64</span>)</span><span id="cb1-47"><a href="#cb1-47"></a>        out <span class="op">=</span> <span class="va">self</span>.linear(x)</span><span id="cb1-48"><a href="#cb1-48"></a>        <span class="cf">return</span> out</span><span id="cb1-49"><a href="#cb1-49"></a></span><span id="cb1-50"><a href="#cb1-50"></a></span><span id="cb1-51"><a href="#cb1-51"></a>model <span class="op">=</span> ConvNet()</span><span id="cb1-52"><a href="#cb1-52"></a><span class="bu">print</span>(model)</span><span id="cb1-53"><a href="#cb1-53"></a></span><span id="cb1-54"><a href="#cb1-54"></a>optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span>INIT_LR)</span><span id="cb1-55"><a href="#cb1-55"></a>loss_func <span class="op">=</span> nn.CrossEntropyLoss()</span><span id="cb1-56"><a href="#cb1-56"></a></span><span id="cb1-57"><a href="#cb1-57"></a><span class="co"># RNN训练</span></span><span id="cb1-58"><a href="#cb1-58"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(EPOCH):</span><span id="cb1-59"><a href="#cb1-59"></a>    <span class="cf">for</span> index, (b_x, b_y) <span class="kw">in</span> <span class="bu">enumerate</span>(train_loader):</span><span id="cb1-60"><a href="#cb1-60"></a>        model.train()</span><span id="cb1-61"><a href="#cb1-61"></a>        <span class="co"># 输入尺寸为(batch_size, channels, height, width)</span></span><span id="cb1-62"><a href="#cb1-62"></a>        output <span class="op">=</span> model(b_x)  <span class="co"># (64, 1, 28, 28)</span></span><span id="cb1-63"><a href="#cb1-63"></a>        loss <span class="op">=</span> loss_func(output, b_y)</span><span id="cb1-64"><a href="#cb1-64"></a>        optimizer.zero_grad()</span><span id="cb1-65"><a href="#cb1-65"></a>        loss.backward()</span><span id="cb1-66"><a href="#cb1-66"></a>        optimizer.step()</span><span id="cb1-67"><a href="#cb1-67"></a></span><span id="cb1-68"><a href="#cb1-68"></a>        <span class="cf">if</span> index <span class="op">%</span> <span class="dv">50</span> <span class="op">==</span> <span class="dv">0</span>:</span><span id="cb1-69"><a href="#cb1-69"></a>            model.<span class="bu">eval</span>()</span><span id="cb1-70"><a href="#cb1-70"></a>            prediction <span class="op">=</span> model(test_x)  <span class="co"># 输出为(2000, 10)</span></span><span id="cb1-71"><a href="#cb1-71"></a>            pred_y <span class="op">=</span> torch.<span class="bu">max</span>(prediction, <span class="dv">1</span>)[<span class="dv">1</span>].data.numpy()</span><span id="cb1-72"><a href="#cb1-72"></a>            accuracy <span class="op">=</span> (pred_y <span class="op">==</span> test_y).<span class="bu">sum</span>() <span class="op">/</span> <span class="bu">float</span>(test_y.size)</span><span id="cb1-73"><a href="#cb1-73"></a>            <span class="bu">print</span>(<span class="ss">f&#39;Epoch: [</span><span class="sc">{</span>index<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">]&#39;</span>, <span class="ss">f&#39;| train loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">&#39;</span>, <span class="ss">f&#39;| test accuracy: </span><span class="sc">{</span>accuracy<span class="sc">}</span><span class="ss">&#39;</span>)</span><span id="cb1-74"><a href="#cb1-74"></a></span><span id="cb1-75"><a href="#cb1-75"></a><span class="co"># 打印测试数据集中的后20个结果</span></span><span id="cb1-76"><a href="#cb1-76"></a>model.<span class="bu">eval</span>()</span><span id="cb1-77"><a href="#cb1-77"></a>prediction <span class="op">=</span> model(test_x[:<span class="dv">20</span>])</span><span id="cb1-78"><a href="#cb1-78"></a>pred_y <span class="op">=</span> torch.<span class="bu">max</span>(prediction, <span class="dv">1</span>)[<span class="dv">1</span>].data.numpy()</span><span id="cb1-79"><a href="#cb1-79"></a><span class="bu">print</span>(pred_y, <span class="st">&#39;prediction number&#39;</span>)</span><span id="cb1-80"><a href="#cb1-80"></a><span class="bu">print</span>(test_y[:<span class="dv">20</span>], <span class="st">&#39;real number&#39;</span>)</span></code></pre></div><p>训练结果如下，可以看到对于这种不太复杂的问题，CNN和RNN都可以得到比较高的精度。</p><figure><img src="/images/ml/CNN-MNIST.png" alt=""><figcaption>使用卷积网络做手写数字识别</figcaption></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;版权声明：本文为博主原创文章，转载请注明原文出处！&lt;/p&gt;
&lt;p&gt;写作时间：2019-03-02 22:24:22&lt;/p&gt;
&lt;h1 id=&quot;使用卷积网络做手写数字识别&quot;&gt;使用卷积网络做手写数字识别&lt;/h1&gt;
&lt;h2 id=&quot;思路分析&quot;&gt;思路分析&lt;/h2&gt;
&lt;p&gt;上篇博文《&lt;
      
    
    </summary>
    
      <category term="深度学习" scheme="http://theonegis.github.io/categories/dl/"/>
    
    
      <category term="PyTorch" scheme="http://theonegis.github.io/tags/PyTorch/"/>
    
      <category term="卷积神经网络" scheme="http://theonegis.github.io/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="CNN" scheme="http://theonegis.github.io/tags/CNN/"/>
    
      <category term="手写识别" scheme="http://theonegis.github.io/tags/%E6%89%8B%E5%86%99%E8%AF%86%E5%88%AB/"/>
    
  </entry>
  
  <entry>
    <title>使用循环神经网络做手写数字识别</title>
    <link href="http://theonegis.github.io/dl/%E4%BD%BF%E7%94%A8%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%81%9A%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/"/>
    <id>http://theonegis.github.io/dl/使用循环神经网络做手写数字识别/</id>
    <published>2019-03-02T13:36:12.000Z</published>
    <updated>2019-03-22T19:39:53.830Z</updated>
    
    <content type="html"><![CDATA[<p>版权声明：本文为博主原创文章，转载请注明原文出处！</p><p>写作时间：2019-03-02 21:36:12</p><h1 id="使用循环神经网络做手写数字识别">使用循环神经网络做手写数字识别</h1><h2 id="思路分析">思路分析</h2><p>做图像识别的使用卷积神经网络CNN是最好的选择，但是其实我们也可以使用循环神经网络RNN做，只是大部分时候没有卷积网络效果好！下面分析一下如何使用RNN做手写数字的识别。</p><ol type="1"><li>数据的下载我们可以直接使用PyTorch中的<code>torchvision.datasets</code>提供的数据接口</li><li>对于每一张图像（28$$28）我们可以将图像的每一行看做一个样本，然后所有行排列起来做成一个有序序列。对于这个序列，我们就可以使用RNN做识别训练了。</li><li>下面的实现中使用一个LSTM+Linear层组合实现（不要使用经典RNN，效果不好），损失函数使用CrossEntropyLoss。</li><li>在实践中设置<code>batch_first=True</code>可以减少一些额外的维度变换和尺寸转换的代码，推荐使用</li></ol><h2 id="pytorch实现">PyTorch实现</h2><div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> torch</span><span id="cb1-2"><a href="#cb1-2"></a><span class="im">from</span> torch <span class="im">import</span> nn</span><span id="cb1-3"><a href="#cb1-3"></a><span class="im">import</span> torchvision.datasets <span class="im">as</span> datasets</span><span id="cb1-4"><a href="#cb1-4"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span><span id="cb1-5"><a href="#cb1-5"></a></span><span id="cb1-6"><a href="#cb1-6"></a>torch.manual_seed(<span class="dv">2019</span>)</span><span id="cb1-7"><a href="#cb1-7"></a></span><span id="cb1-8"><a href="#cb1-8"></a><span class="co"># 超参设置</span></span><span id="cb1-9"><a href="#cb1-9"></a>EPOCH <span class="op">=</span> <span class="dv">1</span>  <span class="co"># 训练EPOCH次，这里为了测试方便只跑一次</span></span><span id="cb1-10"><a href="#cb1-10"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">32</span></span><span id="cb1-11"><a href="#cb1-11"></a>TIME_STEP <span class="op">=</span> <span class="dv">28</span>  <span class="co"># RNN时间跨度（图片高度）</span></span><span id="cb1-12"><a href="#cb1-12"></a>INPUT_SIZE <span class="op">=</span> <span class="dv">28</span>  <span class="co"># RNN输入尺寸（图片宽度）</span></span><span id="cb1-13"><a href="#cb1-13"></a>INIT_LR <span class="op">=</span> <span class="fl">0.01</span>  <span class="co"># 初始学习率</span></span><span id="cb1-14"><a href="#cb1-14"></a>DOWNLOAD_MNIST <span class="op">=</span> <span class="va">True</span>  <span class="co"># 设置是否需要下载数据集</span></span><span id="cb1-15"><a href="#cb1-15"></a></span><span id="cb1-16"><a href="#cb1-16"></a><span class="co"># 使用DataLoader加载训练数据，为了演示方便，对于测试数据只取出2000个样本进行测试</span></span><span id="cb1-17"><a href="#cb1-17"></a>train_data <span class="op">=</span> datasets.MNIST(root<span class="op">=</span><span class="st">&#39;mnist&#39;</span>, train<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transforms.ToTensor(), download<span class="op">=</span>DOWNLOAD_MNIST)</span><span id="cb1-18"><a href="#cb1-18"></a>train_loader <span class="op">=</span> torch.utils.data.DataLoader(dataset<span class="op">=</span>train_data, batch_size<span class="op">=</span>BATCH_SIZE, shuffle<span class="op">=</span><span class="va">True</span>)</span><span id="cb1-19"><a href="#cb1-19"></a>test_data <span class="op">=</span> datasets.MNIST(root<span class="op">=</span><span class="st">&#39;mnist&#39;</span>, train<span class="op">=</span><span class="va">False</span>)</span><span id="cb1-20"><a href="#cb1-20"></a>test_x <span class="op">=</span> test_data.test_data.<span class="bu">type</span>(torch.FloatTensor)[:<span class="dv">2000</span>] <span class="op">/</span> <span class="fl">255.</span></span><span id="cb1-21"><a href="#cb1-21"></a>test_y <span class="op">=</span> test_data.test_labels.numpy()[:<span class="dv">2000</span>]</span><span id="cb1-22"><a href="#cb1-22"></a></span><span id="cb1-23"><a href="#cb1-23"></a></span><span id="cb1-24"><a href="#cb1-24"></a><span class="kw">class</span> RNN(nn.Module):</span><span id="cb1-25"><a href="#cb1-25"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span><span id="cb1-26"><a href="#cb1-26"></a>        <span class="bu">super</span>(RNN, <span class="va">self</span>).<span class="fu">__init__</span>()</span><span id="cb1-27"><a href="#cb1-27"></a>        <span class="va">self</span>.rnn <span class="op">=</span> nn.LSTM(</span><span id="cb1-28"><a href="#cb1-28"></a>            input_size<span class="op">=</span>INPUT_SIZE,</span><span id="cb1-29"><a href="#cb1-29"></a>            hidden_size<span class="op">=</span><span class="dv">64</span>,</span><span id="cb1-30"><a href="#cb1-30"></a>            num_layers<span class="op">=</span><span class="dv">1</span>,</span><span id="cb1-31"><a href="#cb1-31"></a>            batch_first<span class="op">=</span><span class="va">True</span></span><span id="cb1-32"><a href="#cb1-32"></a>        )</span><span id="cb1-33"><a href="#cb1-33"></a>        <span class="va">self</span>.out <span class="op">=</span> nn.Linear(<span class="dv">64</span>, <span class="dv">10</span>)</span><span id="cb1-34"><a href="#cb1-34"></a></span><span id="cb1-35"><a href="#cb1-35"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span><span id="cb1-36"><a href="#cb1-36"></a>        <span class="co"># x shape (batch_size, time_step, input_size)</span></span><span id="cb1-37"><a href="#cb1-37"></a>        <span class="co"># r_out shape (batch_size, time_step, output_size)</span></span><span id="cb1-38"><a href="#cb1-38"></a>        <span class="co"># h_n shape (n_layers, batch_size, hidden_size)</span></span><span id="cb1-39"><a href="#cb1-39"></a>        <span class="co"># h_c shape (n_layers, batch_size, hidden_size)</span></span><span id="cb1-40"><a href="#cb1-40"></a>        r_out, (h_n, h_c) <span class="op">=</span> <span class="va">self</span>.rnn(x)</span><span id="cb1-41"><a href="#cb1-41"></a>        <span class="co"># 取出最后一次循环的r_out传递到全连接层</span></span><span id="cb1-42"><a href="#cb1-42"></a>        out <span class="op">=</span> <span class="va">self</span>.out(r_out[:, <span class="op">-</span><span class="dv">1</span>, :])</span><span id="cb1-43"><a href="#cb1-43"></a>        <span class="cf">return</span> out</span><span id="cb1-44"><a href="#cb1-44"></a></span><span id="cb1-45"><a href="#cb1-45"></a></span><span id="cb1-46"><a href="#cb1-46"></a>rnn <span class="op">=</span> RNN()</span><span id="cb1-47"><a href="#cb1-47"></a><span class="bu">print</span>(rnn)</span><span id="cb1-48"><a href="#cb1-48"></a></span><span id="cb1-49"><a href="#cb1-49"></a>optimizer <span class="op">=</span> torch.optim.Adam(rnn.parameters(), lr<span class="op">=</span>INIT_LR)</span><span id="cb1-50"><a href="#cb1-50"></a>loss_func <span class="op">=</span> nn.CrossEntropyLoss()</span><span id="cb1-51"><a href="#cb1-51"></a></span><span id="cb1-52"><a href="#cb1-52"></a><span class="co"># RNN训练</span></span><span id="cb1-53"><a href="#cb1-53"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(EPOCH):</span><span id="cb1-54"><a href="#cb1-54"></a>    <span class="cf">for</span> step, (b_x, b_y) <span class="kw">in</span> <span class="bu">enumerate</span>(train_loader):</span><span id="cb1-55"><a href="#cb1-55"></a>        <span class="co"># 数据的输入为(batch_size, time_step, input_size)</span></span><span id="cb1-56"><a href="#cb1-56"></a>        b_x <span class="op">=</span> b_x.view(<span class="op">-</span><span class="dv">1</span>, TIME_STEP, INPUT_SIZE)</span><span id="cb1-57"><a href="#cb1-57"></a>        output <span class="op">=</span> rnn(b_x)</span><span id="cb1-58"><a href="#cb1-58"></a>        loss <span class="op">=</span> loss_func(output, b_y)</span><span id="cb1-59"><a href="#cb1-59"></a>        optimizer.zero_grad()</span><span id="cb1-60"><a href="#cb1-60"></a>        loss.backward()</span><span id="cb1-61"><a href="#cb1-61"></a>        optimizer.step()</span><span id="cb1-62"><a href="#cb1-62"></a></span><span id="cb1-63"><a href="#cb1-63"></a>        <span class="cf">if</span> step <span class="op">%</span> <span class="dv">50</span> <span class="op">==</span> <span class="dv">0</span>:</span><span id="cb1-64"><a href="#cb1-64"></a>            prediction <span class="op">=</span> rnn(test_x)  <span class="co"># 输出为(2000, 10)</span></span><span id="cb1-65"><a href="#cb1-65"></a>            pred_y <span class="op">=</span> torch.<span class="bu">max</span>(prediction, <span class="dv">1</span>)[<span class="dv">1</span>].data.numpy()</span><span id="cb1-66"><a href="#cb1-66"></a>            accuracy <span class="op">=</span> (pred_y <span class="op">==</span> test_y).<span class="bu">sum</span>() <span class="op">/</span> <span class="bu">float</span>(test_y.size)</span><span id="cb1-67"><a href="#cb1-67"></a>            <span class="bu">print</span>(<span class="ss">f&#39;Epoch: [</span><span class="sc">{</span>step<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">]&#39;</span>, <span class="ss">f&#39;| train loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">&#39;</span>, <span class="ss">f&#39;| test accuracy: </span><span class="sc">{</span>accuracy<span class="sc">}</span><span class="ss">&#39;</span>)</span><span id="cb1-68"><a href="#cb1-68"></a></span><span id="cb1-69"><a href="#cb1-69"></a><span class="co"># 打印测试数据集中的后20个结果</span></span><span id="cb1-70"><a href="#cb1-70"></a>prediction <span class="op">=</span> rnn(test_x[:<span class="dv">20</span>].view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>))</span><span id="cb1-71"><a href="#cb1-71"></a>pred_y <span class="op">=</span> torch.<span class="bu">max</span>(prediction, <span class="dv">1</span>)[<span class="dv">1</span>].data.numpy()</span><span id="cb1-72"><a href="#cb1-72"></a><span class="bu">print</span>(pred_y, <span class="st">&#39;prediction number&#39;</span>)</span><span id="cb1-73"><a href="#cb1-73"></a><span class="bu">print</span>(test_y[:<span class="dv">20</span>], <span class="st">&#39;real number&#39;</span>)</span></code></pre></div><p>下面是训练结果的截图，可以看到效果还不错！</p><figure><img src="/images/ml/LSTM-MNIST.png" alt=""><figcaption>使用循环神经网络做手写数字识别</figcaption></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;版权声明：本文为博主原创文章，转载请注明原文出处！&lt;/p&gt;
&lt;p&gt;写作时间：2019-03-02 21:36:12&lt;/p&gt;
&lt;h1 id=&quot;使用循环神经网络做手写数字识别&quot;&gt;使用循环神经网络做手写数字识别&lt;/h1&gt;
&lt;h2 id=&quot;思路分析&quot;&gt;思路分析&lt;/h2&gt;
&lt;p&gt;做图
      
    
    </summary>
    
      <category term="深度学习" scheme="http://theonegis.github.io/categories/dl/"/>
    
    
      <category term="PyTorch" scheme="http://theonegis.github.io/tags/PyTorch/"/>
    
      <category term="手写识别" scheme="http://theonegis.github.io/tags/%E6%89%8B%E5%86%99%E8%AF%86%E5%88%AB/"/>
    
      <category term="循环神经网络" scheme="http://theonegis.github.io/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="RNN" scheme="http://theonegis.github.io/tags/RNN/"/>
    
  </entry>
  
  <entry>
    <title>通俗LSTM长短时循环神经网络介绍</title>
    <link href="http://theonegis.github.io/dl/%E9%80%9A%E4%BF%97LSTM%E9%95%BF%E7%9F%AD%E6%97%B6%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BB%8B%E7%BB%8D/"/>
    <id>http://theonegis.github.io/dl/通俗LSTM长短时循环神经网络介绍/</id>
    <published>2019-03-02T10:20:11.000Z</published>
    <updated>2019-03-22T19:39:53.836Z</updated>
    
    <content type="html"><![CDATA[<p>版权声明：本文为博主原创文章，转载请注明原文出处！ 写作时间：2019-03-02 18:20:11 本文部分图片素材来自互联网，如有侵权，请联系作者删除！</p><h1 id="通俗lstm长短时记忆循环神经网络介绍">通俗LSTM长短时记忆循环神经网络介绍</h1><h2 id="lstm图解">LSTM图解</h2><h3 id="处理流程">处理流程</h3><p>在上一篇<a href="https://blog.csdn.net/theonegis/article/details/88084305" target="_blank" rel="noopener">文章</a>中简单介绍了经典RNN模型，并提到了RNN的一些缺点。LSTM（Long Short-Term Memory）解决了经典RNN不能很好地保存长时序信息的缺点，得到了更加广泛地应用。下面简单说说LSTM的流程。</p><figure><img src="/images/ml/Long_Short-Term_Memory.png" alt=""><figcaption>Long Short-Term Memory</figcaption></figure><p>通过对比我们可以发现，LSTM和经典RNN有如下的区别：</p><ul><li>除了中间状态H，还多了一个C</li><li>每个循环网络的单元（Cell）变得复杂了（多了所谓的三道门“遗忘门”（forget gate），“输入门”（input gate）和“输出门”（output gate））</li></ul><p>这里所谓的“门”其实就是选择性地对信息进行过滤，在实践中用<code>sigmoid</code>函数（在图中用<span class="math inline">\(\sigma\)</span>表示）实现。</p><p>首先，<span class="math inline">\(t-1\)</span>时刻的输入<span class="math inline">\(h_{t-1}\)</span>和<span class="math inline">\(x_t\)</span>经过一个线性变换+<code>sigmoid</code>激活以后（这就是所谓的遗忘门），输出<span class="math inline">\(f_t\)</span>。<span class="math inline">\(f_t\)</span>再与<span class="math inline">\(c_{t-1}\)</span>进行相乘（element-wise multiplication）得到一个中间结果。</p><p>然后，<span class="math inline">\(t-1\)</span>时刻的输入<span class="math inline">\(h_{t-1}\)</span>和<span class="math inline">\(x_t\)</span>经过另外一个线性变换+<code>sigmoid</code>激活以后（这就是所谓的输入门），输出<span class="math inline">\(l_t\)</span>。同时，<span class="math inline">\(h_{t-1}\)</span>和<span class="math inline">\(x_t\)</span>经过再另外一个线性变换+<code>tanh</code>激活以后），与<span class="math inline">\(l_t\)</span>相乘得到一个中间结果。这个中间结果和上一步的中间结果相加（element-wise addition）得到<span class="math inline">\(c_t\)</span>。</p><p>最后，<span class="math inline">\(t-1\)</span>时刻的输入<span class="math inline">\(h_{t-1}\)</span>和<span class="math inline">\(x_t\)</span>经过另外一个线性变换+<code>sigmoid</code>激活以后（这就是所谓的输出门），输出<span class="math inline">\(o_t\)</span>。<span class="math inline">\(o_t\)</span>与经过<code>tanh</code>的<span class="math inline">\(c_t\)</span>相乘得到<span class="math inline">\(h_t\)</span>。</p><p>至此，所有的状态更新完毕。</p><h3 id="流程图解">流程图解</h3><p>下面给出上面文字描述的步骤所对应的数学公式：</p><figure><img src="/images/ml/LSTM3-focus-f.png" alt=""><figcaption>LSTM第一步遗忘门</figcaption></figure><figure><img src="/images/ml/LSTM3-focus-i.png" alt=""><figcaption>LSTM第二步输入门</figcaption></figure><figure><img src="/images/ml/LSTM3-focus-C.png" alt=""><figcaption>LSTM得到中间状态C</figcaption></figure><figure><img src="/images/ml/LSTM3-focus-o.png" alt=""><figcaption>LSTM第三步输出门</figcaption></figure><h3 id="总结说明">总结说明</h3><figure><img src="/images/ml/LSTM-Pipeline.png" alt=""><figcaption>LSTM数据管道</figcaption></figure><p>上图的左子图给出了对于每个门的输入和输出，右子图说明了每个门的作用。</p><h2 id="pytorch实战">PyTorch实战</h2><p>我们还是以《<a href="https://blog.csdn.net/theonegis" target="_blank" rel="noopener">最简单的RNN回归模型入门</a>》中的使用Sin预测Cos的例子进行演示，代码跟之间的没有太大的区别，唯一的不同就是在中间状态更新的时候，现在有C和H两种中间状态需要更新。</p><div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> torch</span><span id="cb1-2"><a href="#cb1-2"></a><span class="im">from</span> torch <span class="im">import</span> nn</span><span id="cb1-3"><a href="#cb1-3"></a><span class="im">import</span> numpy <span class="im">as</span> np</span><span id="cb1-4"><a href="#cb1-4"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span><span id="cb1-5"><a href="#cb1-5"></a></span><span id="cb1-6"><a href="#cb1-6"></a>torch.manual_seed(<span class="dv">2019</span>)</span><span id="cb1-7"><a href="#cb1-7"></a></span><span id="cb1-8"><a href="#cb1-8"></a><span class="co"># 超参设置</span></span><span id="cb1-9"><a href="#cb1-9"></a>TIME_STEP <span class="op">=</span> <span class="dv">20</span>  <span class="co"># RNN时间步长</span></span><span id="cb1-10"><a href="#cb1-10"></a>INPUT_SIZE <span class="op">=</span> <span class="dv">1</span>  <span class="co"># RNN输入尺寸</span></span><span id="cb1-11"><a href="#cb1-11"></a>INIT_LR <span class="op">=</span> <span class="fl">0.02</span>  <span class="co"># 初始学习率</span></span><span id="cb1-12"><a href="#cb1-12"></a>N_EPOCHS <span class="op">=</span> <span class="dv">100</span>  <span class="co"># 训练回数</span></span><span id="cb1-13"><a href="#cb1-13"></a></span><span id="cb1-14"><a href="#cb1-14"></a></span><span id="cb1-15"><a href="#cb1-15"></a><span class="kw">class</span> RNN(nn.Module):</span><span id="cb1-16"><a href="#cb1-16"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span><span id="cb1-17"><a href="#cb1-17"></a>        <span class="bu">super</span>(RNN, <span class="va">self</span>).<span class="fu">__init__</span>()</span><span id="cb1-18"><a href="#cb1-18"></a>        <span class="va">self</span>.rnn <span class="op">=</span> nn.LSTM(</span><span id="cb1-19"><a href="#cb1-19"></a>            input_size<span class="op">=</span>INPUT_SIZE,</span><span id="cb1-20"><a href="#cb1-20"></a>            hidden_size<span class="op">=</span><span class="dv">32</span>,  <span class="co"># RNN隐藏神经元个数</span></span><span id="cb1-21"><a href="#cb1-21"></a>            num_layers<span class="op">=</span><span class="dv">1</span>,  <span class="co"># RNN隐藏层个数</span></span><span id="cb1-22"><a href="#cb1-22"></a>        )</span><span id="cb1-23"><a href="#cb1-23"></a>        <span class="va">self</span>.out <span class="op">=</span> nn.Linear(<span class="dv">32</span>, <span class="dv">1</span>)</span><span id="cb1-24"><a href="#cb1-24"></a></span><span id="cb1-25"><a href="#cb1-25"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, h):</span><span id="cb1-26"><a href="#cb1-26"></a>        <span class="co"># x (time_step, batch_size, input_size)</span></span><span id="cb1-27"><a href="#cb1-27"></a>        <span class="co"># h (n_layers, batch, hidden_size)</span></span><span id="cb1-28"><a href="#cb1-28"></a>        <span class="co"># out (time_step, batch_size, hidden_size)</span></span><span id="cb1-29"><a href="#cb1-29"></a>        out, h <span class="op">=</span> <span class="va">self</span>.rnn(x, h)</span><span id="cb1-30"><a href="#cb1-30"></a>        prediction <span class="op">=</span> <span class="va">self</span>.out(out)</span><span id="cb1-31"><a href="#cb1-31"></a>        <span class="cf">return</span> prediction, h</span><span id="cb1-32"><a href="#cb1-32"></a></span><span id="cb1-33"><a href="#cb1-33"></a></span><span id="cb1-34"><a href="#cb1-34"></a>rnn <span class="op">=</span> RNN()</span><span id="cb1-35"><a href="#cb1-35"></a><span class="bu">print</span>(rnn)</span><span id="cb1-36"><a href="#cb1-36"></a></span><span id="cb1-37"><a href="#cb1-37"></a>optimizer <span class="op">=</span> torch.optim.Adam(rnn.parameters(), lr<span class="op">=</span>INIT_LR)</span><span id="cb1-38"><a href="#cb1-38"></a>loss_func <span class="op">=</span> nn.MSELoss()</span><span id="cb1-39"><a href="#cb1-39"></a>h_state <span class="op">=</span> <span class="va">None</span>  <span class="co"># 初始化隐藏层</span></span><span id="cb1-40"><a href="#cb1-40"></a></span><span id="cb1-41"><a href="#cb1-41"></a>plt.figure()</span><span id="cb1-42"><a href="#cb1-42"></a>plt.ion()</span><span id="cb1-43"><a href="#cb1-43"></a><span class="cf">for</span> step <span class="kw">in</span> <span class="bu">range</span>(N_EPOCHS):</span><span id="cb1-44"><a href="#cb1-44"></a>    start, end <span class="op">=</span> step <span class="op">*</span> np.pi, (step <span class="op">+</span> <span class="dv">1</span>) <span class="op">*</span> np.pi  <span class="co"># 时间跨度</span></span><span id="cb1-45"><a href="#cb1-45"></a>    <span class="co"># 使用Sin函数预测Cos函数</span></span><span id="cb1-46"><a href="#cb1-46"></a>    steps <span class="op">=</span> np.linspace(start, end, TIME_STEP, dtype<span class="op">=</span>np.float32, endpoint<span class="op">=</span><span class="va">False</span>)</span><span id="cb1-47"><a href="#cb1-47"></a>    x_np <span class="op">=</span> np.sin(steps)</span><span id="cb1-48"><a href="#cb1-48"></a>    y_np <span class="op">=</span> np.cos(steps)</span><span id="cb1-49"><a href="#cb1-49"></a>    x <span class="op">=</span> torch.from_numpy(x_np[:, np.newaxis, np.newaxis])  <span class="co"># 尺寸大小为(time_step, batch, input_size)</span></span><span id="cb1-50"><a href="#cb1-50"></a>    y <span class="op">=</span> torch.from_numpy(y_np[:, np.newaxis, np.newaxis])</span><span id="cb1-51"><a href="#cb1-51"></a></span><span id="cb1-52"><a href="#cb1-52"></a>    prediction, h_state <span class="op">=</span> rnn(x, h_state)  <span class="co"># RNN输出（预测结果，隐藏状态）</span></span><span id="cb1-53"><a href="#cb1-53"></a>    h_state <span class="op">=</span> (h_state[<span class="dv">0</span>].detach(), h_state[<span class="dv">1</span>].detach())  <span class="co"># 注意这里和原来的RNN的不同</span></span><span id="cb1-54"><a href="#cb1-54"></a>    loss <span class="op">=</span> loss_func(prediction, y)</span><span id="cb1-55"><a href="#cb1-55"></a>    optimizer.zero_grad()</span><span id="cb1-56"><a href="#cb1-56"></a>    loss.backward()</span><span id="cb1-57"><a href="#cb1-57"></a>    optimizer.step()</span><span id="cb1-58"><a href="#cb1-58"></a></span><span id="cb1-59"><a href="#cb1-59"></a>    <span class="co"># 绘制中间结果</span></span><span id="cb1-60"><a href="#cb1-60"></a>    plt.cla()</span><span id="cb1-61"><a href="#cb1-61"></a>    plt.plot(steps, y_np, <span class="st">&#39;r-&#39;</span>)</span><span id="cb1-62"><a href="#cb1-62"></a>    plt.plot(steps, prediction.data.numpy().flatten(), <span class="st">&#39;b-&#39;</span>)</span><span id="cb1-63"><a href="#cb1-63"></a>    plt.draw()</span><span id="cb1-64"><a href="#cb1-64"></a>    plt.pause(<span class="fl">0.1</span>)</span><span id="cb1-65"><a href="#cb1-65"></a>plt.ioff()</span><span id="cb1-66"><a href="#cb1-66"></a>plt.show()</span></code></pre></div><p>当<code>TIME_STEP</code>设置为20的时候，输出结果如下：</p><figure><img src="/images/ml/LSTM-Sin-20.png" alt=""><figcaption>LSTM Sin预测Cos</figcaption></figure><h2 id="参考资料">参考资料</h2><ol type="1"><li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">Understanding LSTM Networks</a></li><li><a href="https://medium.com/mlreview/understanding-lstm-and-its-diagrams-37e2f46f1714" target="_blank" rel="noopener">Understanding LSTM and its diagrams</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;版权声明：本文为博主原创文章，转载请注明原文出处！ 写作时间：2019-03-02 18:20:11 本文部分图片素材来自互联网，如有侵权，请联系作者删除！&lt;/p&gt;
&lt;h1 id=&quot;通俗lstm长短时记忆循环神经网络介绍&quot;&gt;通俗LSTM长短时记忆循环神经网络介绍&lt;/h1&gt;

      
    
    </summary>
    
      <category term="深度学习" scheme="http://theonegis.github.io/categories/dl/"/>
    
    
      <category term="循环神经网络" scheme="http://theonegis.github.io/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="长短时" scheme="http://theonegis.github.io/tags/%E9%95%BF%E7%9F%AD%E6%97%B6/"/>
    
  </entry>
  
  <entry>
    <title>最简单的RNN回归模型入门(PyTorch)</title>
    <link href="http://theonegis.github.io/dl/%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84RNN%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E5%85%A5%E9%97%A8-PyTorch/"/>
    <id>http://theonegis.github.io/dl/最简单的RNN回归模型入门-PyTorch/</id>
    <published>2019-03-02T04:46:15.000Z</published>
    <updated>2019-03-22T19:39:53.834Z</updated>
    
    <content type="html"><![CDATA[<p>版权声明：本文为博主原创文章，转载请注明原文出处！ 写作时间：2019-03-02 12:46:15</p><p>本文部分图片素材来自互联网，如有侵权，请联系作者删除！</p><h1 id="最简单的rnn回归模型入门pytorch版">最简单的RNN回归模型入门（PyTorch版）</h1><h2 id="rnn入门介绍">RNN入门介绍</h2><p>至于RNN的能做什么，擅长什么，这里不赘述。如果不清楚，请先维基一下，那里比我说得更加清楚。</p><p>我们首先来来看一张经典的RNN模型示意图！</p><figure><img src="/images/ml/Recurrent-Neural-Network.png" alt=""><figcaption>Recurrent Neural Network</figcaption></figure><p>图分左右两边：左边给出的RNN是一个抽象的循环结构，右边是左边RNN展开以后的形式。先来看右边的结构，从下往上依次是序列数据的输入X（图中的绿色结构，可以是时间序列，也可以是文本序列等等）。对于t时刻的x经过一个线性变换（U是变换的权重），然后与t-1时刻经过线性变换V的h相加，再经过一个 非线性激活（一般使用tanh或者relu函数）以后，形成一个t时刻的中间状态h，然后再经过一个线性变换（W）输出o ，最后再经过一个非线性激活（可以是sigmoid函数或者softmax等函数）形成最后的输出y。</p><p>上面的文字描述，可以形式化表示为下面的公式：</p><p><span class="math display">\[a^t = Vh^{t-1} + Ux^t + b \\ h^t=tanh(a^t) \\ o^t=Wh^t + c\\ y^t=sigmoid(o^t)\]</span></p><p>是不是公式能比文字更加说明问题！</p><p>再来说左边的结构，坐标的结构表明后面地展开网络中的U，V，W参数都是在共享的，就是说不管我们的序列有多长，都是共享这一套参数的。这是RNN很重要的一个特性。</p><p>RNN的隐藏层可以有多层，但是RNN中我们的隐藏层一般不会设置太多，因为在横向上有很长的序列扩展形成的网络，这部分特征是我们更加关注的。最后，需要说明的是RNN可以是单向的，也可以是双向的。</p><h2 id="pytorch中的rnn">PyTorch中的RNN</h2><p>下面我们以一个最简单的回归问题使用正弦sin函数预测余弦cos函数，介绍如何使用PyTorch实现RNN模型。</p><p>先来看一下PyTorch中<a href="https://pytorch.org/docs/stable/nn.html#rnn" target="_blank" rel="noopener">RNN</a>类的原型：</p><figure><img src="/images/ml/RNNClass.png" alt=""><figcaption>torch.nn.RNN</figcaption></figure><ul><li>必选参数<code>input_size</code>指定输入序列中单个样本的大小尺寸，比如在NLP中我们可能用用一个10000个长度的向量表示一个单词，则这个<code>input_size</code>就是10000。在咱们的回归案例中，一个序列中包含若干点，而每个点的所代表的函数值（Y）作为一个样本，则咱们案例中的<code>input_size</code>为1。这个参数需要根据自己的实际问题确定。</li><li>必选参数<code>hidden_size</code>指的是隐藏层中输出特征的大小，这个是自定义的超参数。</li><li>必选参数<code>num_layers</code>指的是纵向的隐藏层的个数，根据实际问题我们一般可以选择1~10层。</li><li>可选参数<code>batch_first</code>指定是否将<code>batch_size</code>作为输入输出张量的第一个维度，如果是，则输入的尺寸为（<code>batch_size</code>， <code>seq_length</code>，<code>input_size</code>），否则，默认的顺序是（<code>seq_length</code>，<code>batch_size</code>， <code>input_size</code>）。</li><li>可选参数<code>bidirectional</code>指定是否使用双向RNN。</li></ul><p>下面再来说说RNN输入输出尺寸的问题，了解了这个可以让我们我们调试代码的时候更加清晰。下面是PyTorch官方的说明：</p><figure><img src="/images/ml/RNNInOut.png" alt=""><figcaption>RNN的输入输出</figcaption></figure><p>对于RNN的输入包括输入序列和一个初始化的隐藏状态<span class="math inline">\(h_0\)</span>。输入序列尺寸默认是（<code>sequence_length</code>，<code>batch_size</code>， <code>input_size</code>），所以如果我们的数据形式不是这样的，则需要手动调整为这种类型的格式。</p><p>隐藏状态<span class="math inline">\(h_i\)</span>的尺寸是（<code>num_layers * num_directions</code>， <code>batch_size</code>，<code>hidden_size</code>）。单向RNN的<code>num_directions</code>为1，双向RNN的<code>num_directions</code>为2。</p><p>他们的尺寸为什么是这样的呢？这得根据本文开头的那个公式计算，即就是矩阵的相乘需要满足矩阵尺寸的关系，聪明的你想明白了吗？</p><p>输出的尺寸为 （<code>sequence_length</code>， <code>batch_size</code>， <code>num_directions * hidden_size</code>）</p><p>每一次RNN运行结果输出中还会附带输出中间隐藏状态<span class="math inline">\(h_i\)</span>，当然这个尺寸和初始的隐藏状态相同。</p><p>下面以一个简单的例子说明怎么在程序中查看他们的尺寸：</p><div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> torch</span><span id="cb1-2"><a href="#cb1-2"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span><span id="cb1-3"><a href="#cb1-3"></a></span><span id="cb1-4"><a href="#cb1-4"></a>rnn <span class="op">=</span> nn.RNN(<span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">2</span>)</span><span id="cb1-5"><a href="#cb1-5"></a>inputs <span class="op">=</span> torch.randn(<span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">10</span>)  <span class="co"># (time_step, batch_size, input_size)</span></span><span id="cb1-6"><a href="#cb1-6"></a>h0 <span class="op">=</span> torch.randn(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">20</span>)  <span class="co"># (num_layers, batch_size, hidden_size)</span></span><span id="cb1-7"><a href="#cb1-7"></a>output, hn <span class="op">=</span> rnn(inputs, h0)</span><span id="cb1-8"><a href="#cb1-8"></a><span class="bu">print</span>(output.shape)  <span class="co"># (time_step, batch_size, hidden_size)</span></span><span id="cb1-9"><a href="#cb1-9"></a></span><span id="cb1-10"><a href="#cb1-10"></a><span class="cf">for</span> name, param <span class="kw">in</span> rnn.named_parameters():</span><span id="cb1-11"><a href="#cb1-11"></a>    <span class="cf">if</span> param.requires_grad:</span><span id="cb1-12"><a href="#cb1-12"></a>        <span class="bu">print</span>(name, param.size())</span></code></pre></div><p>其输出结果如下：</p><pre><code>torch.Size([5, 3, 20])weight_ih_l0 torch.Size([20, 10])weight_hh_l0 torch.Size([20, 20])bias_ih_l0 torch.Size([20])bias_hh_l0 torch.Size([20])weight_ih_l1 torch.Size([20, 20])weight_hh_l1 torch.Size([20, 20])bias_ih_l1 torch.Size([20])bias_hh_l1 torch.Size([20])</code></pre><p>这里的<code>weight_ih_l0</code>表示的是RNN隐藏层第一层的权重U，<code>weight_hh_l0</code>表示的隐藏层第一层的权重V，类似的<code>bias</code>开头的表示偏置或者叫增益（我不知道中文如何翻译），以<code>l数字</code>结尾的表示第几层的权重或者偏置。</p><h2 id="代码实现与结果分析">代码实现与结果分析</h2><p>好了，搞清楚了RNN的基本原理以及PyTorch中RNN类的输入输出参数要求，我们下面实现我们的回归案例。</p><p>比较重要的几个超参数是：<code>TIME_STEP</code>指定输入序列的长度（一个序列中包含的函数值的个数），<code>INPUT_SIZE</code>是1，表示一个序列中的每个样本包含一个函数值。</p><p>我们自定义的RNN类包含两个模型：一个<code>nn.RNN</code>层，一个<code>nn.Linear</code>层，注意<code>forward</code>函数的实现，观察每个变量的尺寸（注释中给出了答案）。</p><div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="im">import</span> torch</span><span id="cb3-2"><a href="#cb3-2"></a><span class="im">from</span> torch <span class="im">import</span> nn</span><span id="cb3-3"><a href="#cb3-3"></a><span class="im">import</span> numpy <span class="im">as</span> np</span><span id="cb3-4"><a href="#cb3-4"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span><span id="cb3-5"><a href="#cb3-5"></a></span><span id="cb3-6"><a href="#cb3-6"></a>torch.manual_seed(<span class="dv">2019</span>)</span><span id="cb3-7"><a href="#cb3-7"></a></span><span id="cb3-8"><a href="#cb3-8"></a><span class="co"># 超参设置</span></span><span id="cb3-9"><a href="#cb3-9"></a>TIME_STEP <span class="op">=</span> <span class="dv">10</span>  <span class="co"># RNN时间步长</span></span><span id="cb3-10"><a href="#cb3-10"></a>INPUT_SIZE <span class="op">=</span> <span class="dv">1</span>  <span class="co"># RNN输入尺寸</span></span><span id="cb3-11"><a href="#cb3-11"></a>INIT_LR <span class="op">=</span> <span class="fl">0.02</span>  <span class="co"># 初始学习率</span></span><span id="cb3-12"><a href="#cb3-12"></a>N_EPOCHS <span class="op">=</span> <span class="dv">100</span>  <span class="co"># 训练回数</span></span><span id="cb3-13"><a href="#cb3-13"></a></span><span id="cb3-14"><a href="#cb3-14"></a></span><span id="cb3-15"><a href="#cb3-15"></a><span class="kw">class</span> RNN(nn.Module):</span><span id="cb3-16"><a href="#cb3-16"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span><span id="cb3-17"><a href="#cb3-17"></a>        <span class="bu">super</span>(RNN, <span class="va">self</span>).<span class="fu">__init__</span>()</span><span id="cb3-18"><a href="#cb3-18"></a>        <span class="va">self</span>.rnn <span class="op">=</span> nn.RNN(</span><span id="cb3-19"><a href="#cb3-19"></a>            input_size<span class="op">=</span>INPUT_SIZE,</span><span id="cb3-20"><a href="#cb3-20"></a>            hidden_size<span class="op">=</span><span class="dv">32</span>,  <span class="co"># RNN隐藏神经元个数</span></span><span id="cb3-21"><a href="#cb3-21"></a>            num_layers<span class="op">=</span><span class="dv">1</span>,  <span class="co"># RNN隐藏层个数</span></span><span id="cb3-22"><a href="#cb3-22"></a>        )</span><span id="cb3-23"><a href="#cb3-23"></a>        <span class="va">self</span>.out <span class="op">=</span> nn.Linear(<span class="dv">32</span>, <span class="dv">1</span>)</span><span id="cb3-24"><a href="#cb3-24"></a></span><span id="cb3-25"><a href="#cb3-25"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, h):</span><span id="cb3-26"><a href="#cb3-26"></a>        <span class="co"># x (time_step, batch_size, input_size)</span></span><span id="cb3-27"><a href="#cb3-27"></a>        <span class="co"># h (n_layers, batch, hidden_size)</span></span><span id="cb3-28"><a href="#cb3-28"></a>        <span class="co"># out (time_step, batch_size, hidden_size)</span></span><span id="cb3-29"><a href="#cb3-29"></a>        out, h <span class="op">=</span> <span class="va">self</span>.rnn(x, h)</span><span id="cb3-30"><a href="#cb3-30"></a>        prediction <span class="op">=</span> <span class="va">self</span>.out(out)</span><span id="cb3-31"><a href="#cb3-31"></a>        <span class="cf">return</span> prediction, h</span><span id="cb3-32"><a href="#cb3-32"></a></span><span id="cb3-33"><a href="#cb3-33"></a></span><span id="cb3-34"><a href="#cb3-34"></a>rnn <span class="op">=</span> RNN()</span><span id="cb3-35"><a href="#cb3-35"></a><span class="bu">print</span>(rnn)</span><span id="cb3-36"><a href="#cb3-36"></a></span><span id="cb3-37"><a href="#cb3-37"></a>optimizer <span class="op">=</span> torch.optim.Adam(rnn.parameters(), lr<span class="op">=</span>INIT_LR)</span><span id="cb3-38"><a href="#cb3-38"></a>loss_func <span class="op">=</span> nn.MSELoss()</span><span id="cb3-39"><a href="#cb3-39"></a>h_state <span class="op">=</span> <span class="va">None</span>  <span class="co"># 初始化隐藏层</span></span><span id="cb3-40"><a href="#cb3-40"></a></span><span id="cb3-41"><a href="#cb3-41"></a>plt.figure()</span><span id="cb3-42"><a href="#cb3-42"></a>plt.ion()</span><span id="cb3-43"><a href="#cb3-43"></a><span class="cf">for</span> step <span class="kw">in</span> <span class="bu">range</span>(N_EPOCHS):</span><span id="cb3-44"><a href="#cb3-44"></a>    start, end <span class="op">=</span> step <span class="op">*</span> np.pi, (step <span class="op">+</span> <span class="dv">1</span>) <span class="op">*</span> np.pi  <span class="co"># 时间跨度</span></span><span id="cb3-45"><a href="#cb3-45"></a>    <span class="co"># 使用Sin函数预测Cos函数</span></span><span id="cb3-46"><a href="#cb3-46"></a>    steps <span class="op">=</span> np.linspace(start, end, TIME_STEP, dtype<span class="op">=</span>np.float32, endpoint<span class="op">=</span><span class="va">False</span>)</span><span id="cb3-47"><a href="#cb3-47"></a>    x_np <span class="op">=</span> np.sin(steps)</span><span id="cb3-48"><a href="#cb3-48"></a>    y_np <span class="op">=</span> np.cos(steps)</span><span id="cb3-49"><a href="#cb3-49"></a>    x <span class="op">=</span> torch.from_numpy(x_np[:, np.newaxis, np.newaxis])  <span class="co"># 尺寸大小为(time_step, batch, input_size)</span></span><span id="cb3-50"><a href="#cb3-50"></a>    y <span class="op">=</span> torch.from_numpy(y_np[:, np.newaxis, np.newaxis])</span><span id="cb3-51"><a href="#cb3-51"></a></span><span id="cb3-52"><a href="#cb3-52"></a>    prediction, h_state <span class="op">=</span> rnn(x, h_state)  <span class="co"># RNN输出（预测结果，隐藏状态）</span></span><span id="cb3-53"><a href="#cb3-53"></a>    h_state <span class="op">=</span> h_state.detach()  <span class="co"># 这一行很重要，将每一次输出的中间状态传递下去(不带梯度)</span></span><span id="cb3-54"><a href="#cb3-54"></a>    loss <span class="op">=</span> loss_func(prediction, y)</span><span id="cb3-55"><a href="#cb3-55"></a>    optimizer.zero_grad()</span><span id="cb3-56"><a href="#cb3-56"></a>    loss.backward()</span><span id="cb3-57"><a href="#cb3-57"></a>    optimizer.step()</span><span id="cb3-58"><a href="#cb3-58"></a></span><span id="cb3-59"><a href="#cb3-59"></a>    <span class="co"># 绘制中间结果</span></span><span id="cb3-60"><a href="#cb3-60"></a>    plt.cla()</span><span id="cb3-61"><a href="#cb3-61"></a>    plt.plot(steps, y_np, <span class="st">&#39;r-&#39;</span>)</span><span id="cb3-62"><a href="#cb3-62"></a>    plt.plot(steps, prediction.data.numpy().flatten(), <span class="st">&#39;b-&#39;</span>)</span><span id="cb3-63"><a href="#cb3-63"></a>    plt.draw()</span><span id="cb3-64"><a href="#cb3-64"></a>    plt.pause(<span class="fl">0.1</span>)</span><span id="cb3-65"><a href="#cb3-65"></a>plt.ioff()</span><span id="cb3-66"><a href="#cb3-66"></a>plt.show()</span></code></pre></div><p>最后的结果如下：</p><figure><img src="/images/ml/RNNSinCos.gif" alt=""><figcaption>RNN使用Sin预测Cos</figcaption></figure><p>最后放一个当<code>TIME_STEP</code>分别等于10和20的最终预测结果的对比图：</p><figure><img src="/images/ml/Time-Step-10.png" alt=""><figcaption>RNN TIME_STEP等于10</figcaption></figure><figure><img src="/images/ml/Time-Step-20.png" alt=""><figcaption>RNN TIME_STEP=20</figcaption></figure><p>第一张是<code>TIME_STEP</code>=10的预测结果，第二张是<code>TIME_STEP</code>=20的预测结果。为什么当<code>TIME_STEP</code>=20的预测结果差得十万八千里呢？</p><p>这是因为经典的RNN存在梯度爆炸和梯度弥散问题（我尝试修剪了梯度可是结果还是很差，不知道是不是其它原因），对长时序的预测表现很不好，所以才有了后来的LSTM和GRU等RNN变种。实际现在已经很少使用经典RNN了。有时间在说说LSTM吧，欢迎关注！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;版权声明：本文为博主原创文章，转载请注明原文出处！ 写作时间：2019-03-02 12:46:15&lt;/p&gt;
&lt;p&gt;本文部分图片素材来自互联网，如有侵权，请联系作者删除！&lt;/p&gt;
&lt;h1 id=&quot;最简单的rnn回归模型入门pytorch版&quot;&gt;最简单的RNN回归模型入门（Py
      
    
    </summary>
    
      <category term="深度学习" scheme="http://theonegis.github.io/categories/dl/"/>
    
    
      <category term="PyTorch" scheme="http://theonegis.github.io/tags/PyTorch/"/>
    
      <category term="RNN" scheme="http://theonegis.github.io/tags/RNN/"/>
    
  </entry>
  
  <entry>
    <title>LeetCode-Longest Palindromic Subsequence</title>
    <link href="http://theonegis.github.io/algorithm/LeetCode-Longest-Palindromic-Subsequence/"/>
    <id>http://theonegis.github.io/algorithm/LeetCode-Longest-Palindromic-Subsequence/</id>
    <published>2019-02-10T03:44:52.000Z</published>
    <updated>2019-03-22T19:39:53.823Z</updated>
    
    <content type="html"><![CDATA[<p>版权声明：本文为博主原创文章，转载请注明原文出处！ 写作时间：2019-02-10 11:44:52</p><h1 id="longest-palindromic-subsequence">Longest Palindromic Subsequence</h1><h2 id="题目描述">题目描述</h2><p>这是LeetCode的第516道题目：<a href="https://leetcode.com/problems/longest-palindromic-subsequence/" target="_blank" rel="noopener">516. Longest Palindromic Subsequence</a>。</p><p>Given a string s, find the longest palindromic subsequence’s length in s. You may assume that the maximum length of s is 1000.</p><p><strong>Example 1:</strong> Input:</p><pre><code>&quot;bbbab&quot;</code></pre><p>Output:</p><pre><code>4</code></pre><p>One possible longest palindromic subsequence is “bbbb”.</p><p><strong>Example 2:</strong> Input:</p><pre><code>&quot;cbbd&quot;</code></pre><p>Output:</p><pre><code>2</code></pre><p>One possible longest palindromic subsequence is “bb”.</p><p>题目要求我们计算出给定字符串中的最长回文序列（这里的序列不是一定要在给定字符串中连续排列的，就是挑出的单个字符按其在给定字符串中的顺序排列以后是回文即可）</p><h2 id="思路分析">思路分析</h2><p>其实，思路跟第647道题目<a href="https://leetcode.com/problems/palindromic-substrings/" target="_blank" rel="noopener">Palindromic Substrings</a>是类似的，可以采用动态规划进行。但是因为回文序列不是给定字符串的连续子串，貌似不能使用中心扩散法求解。</p><p>使用动态规划，我们设<code>dp[i][j]</code>表示从第<code>i</code>个字符到到<code>j</code>个字符回文序列的长度，则有：</p><ol type="1"><li>当<code>s[i] == s[j]</code>时，<code>dp[i][j] = dp[i+1][j-1] + 2</code></li><li>当<code>s[i] != s[j]</code>时，<code>dp[i][j] = max(dp[i+1][j], dp[i][j-1])</code></li></ol><h2 id="c实现">C++实现</h2><div class="sourceCode" id="cb5"><pre class="sourceCode c++"><code class="sourceCode cpp"><span id="cb5-1"><a href="#cb5-1"></a><span class="kw">class</span> Solution {</span><span id="cb5-2"><a href="#cb5-2"></a><span class="kw">public</span>:</span><span id="cb5-3"><a href="#cb5-3"></a>    <span class="dt">int</span> longestPalindromeSubseq(string s) {</span><span id="cb5-4"><a href="#cb5-4"></a>        <span class="at">const</span> <span class="dt">int</span> length = s.length();</span><span id="cb5-5"><a href="#cb5-5"></a>        vector&lt;vector&lt;<span class="dt">int</span>&gt;&gt; dp(length, vector&lt;<span class="dt">int</span>&gt;(length));</span><span id="cb5-6"><a href="#cb5-6"></a>        <span class="cf">for</span> (<span class="kw">auto</span> i = length - <span class="dv">1</span>; i &gt;= <span class="dv">0</span>; --i) {</span><span id="cb5-7"><a href="#cb5-7"></a>            dp[i][i] = <span class="dv">1</span>;</span><span id="cb5-8"><a href="#cb5-8"></a>            <span class="cf">for</span> (<span class="kw">auto</span> j = i + <span class="dv">1</span>; j &lt; length; ++j) {</span><span id="cb5-9"><a href="#cb5-9"></a>                dp[i][j] = s[i] == s[j] ?</span><span id="cb5-10"><a href="#cb5-10"></a>                        dp[i + <span class="dv">1</span>][j - <span class="dv">1</span>] + <span class="dv">2</span> :</span><span id="cb5-11"><a href="#cb5-11"></a>                        max(dp[i + <span class="dv">1</span>][j], dp[i][j - <span class="dv">1</span>]);</span><span id="cb5-12"><a href="#cb5-12"></a>            }</span><span id="cb5-13"><a href="#cb5-13"></a>        }</span><span id="cb5-14"><a href="#cb5-14"></a>        <span class="cf">return</span> dp[<span class="dv">0</span>][length - <span class="dv">1</span>];</span><span id="cb5-15"><a href="#cb5-15"></a>    }</span><span id="cb5-16"><a href="#cb5-16"></a>};</span></code></pre></div><h2 id="scala实现">Scala实现</h2><p>Scala版本是对C++版本的翻译</p><div class="sourceCode" id="cb6"><pre class="sourceCode scala"><code class="sourceCode scala"><span id="cb6-1"><a href="#cb6-1"></a><span class="kw">object</span> Solution {</span><span id="cb6-2"><a href="#cb6-2"></a>  <span class="kw">def</span> <span class="fu">longestPalindromeSubseq</span>(s: String): Int = {</span><span id="cb6-3"><a href="#cb6-3"></a>    <span class="kw">val</span> length = s.<span class="fu">length</span></span><span id="cb6-4"><a href="#cb6-4"></a>    <span class="kw">val</span> dp = Array.<span class="fu">ofDim</span>[Int](length, length)</span><span id="cb6-5"><a href="#cb6-5"></a>    <span class="kw">for</span> (i &lt;- length - <span class="dv">1</span> to <span class="dv">0</span> by <span class="dv">-1</span>) {</span><span id="cb6-6"><a href="#cb6-6"></a>      <span class="fu">dp</span>(i)(i) = <span class="dv">1</span></span><span id="cb6-7"><a href="#cb6-7"></a>      <span class="kw">for</span> (j &lt;- i + <span class="dv">1</span> until length) {</span><span id="cb6-8"><a href="#cb6-8"></a>        <span class="fu">dp</span>(i)(j) = <span class="kw">if</span> (<span class="fu">s</span>(i) == <span class="fu">s</span>(j)) <span class="fu">dp</span>(i + <span class="dv">1</span>)(j - <span class="dv">1</span>) + <span class="dv">2</span></span><span id="cb6-9"><a href="#cb6-9"></a>        <span class="kw">else</span> math.<span class="fu">max</span>(<span class="fu">dp</span>(i + <span class="dv">1</span>)(j), <span class="fu">dp</span>(i)(j - <span class="dv">1</span>))</span><span id="cb6-10"><a href="#cb6-10"></a>      }</span><span id="cb6-11"><a href="#cb6-11"></a>    }</span><span id="cb6-12"><a href="#cb6-12"></a>    <span class="kw">return</span> <span class="fu">dp</span>(<span class="dv">0</span>)(length - <span class="dv">1</span>)</span><span id="cb6-13"><a href="#cb6-13"></a>  }</span><span id="cb6-14"><a href="#cb6-14"></a>}</span></code></pre></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;版权声明：本文为博主原创文章，转载请注明原文出处！ 写作时间：2019-02-10 11:44:52&lt;/p&gt;
&lt;h1 id=&quot;longest-palindromic-subsequence&quot;&gt;Longest Palindromic Subsequence&lt;/h1&gt;
&lt;h2 
      
    
    </summary>
    
      <category term="算法" scheme="http://theonegis.github.io/categories/algorithm/"/>
    
    
      <category term="LeetCode" scheme="http://theonegis.github.io/tags/LeetCode/"/>
    
      <category term="动态规划" scheme="http://theonegis.github.io/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
      <category term="回文" scheme="http://theonegis.github.io/tags/%E5%9B%9E%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>Longest Palindromic Substring</title>
    <link href="http://theonegis.github.io/algorithm/Longest-Palindromic-Substring/"/>
    <id>http://theonegis.github.io/algorithm/Longest-Palindromic-Substring/</id>
    <published>2019-02-09T16:04:34.000Z</published>
    <updated>2019-03-22T19:39:53.824Z</updated>
    
    <content type="html"><![CDATA[<p>版权声明：本文为博主原创文章，转载请注明原文出处！</p><p>写作时间：2019-02-10 00:04:34</p><h1 id="leetcode-longest-palindromic-substring">LeetCode-Longest Palindromic Substring</h1><h2 id="题目描述">题目描述</h2><p>LeetCode第5道题目：<a href="https://leetcode.com/problems/longest-palindromic-substring/" target="_blank" rel="noopener">5. Longest Palindromic Substring</a></p><p>Given a string <strong>s</strong>, find the longest palindromic substring in <strong>s</strong>. You may assume that the maximum length of <strong>s</strong> is 1000.</p><p><strong>Example 1:</strong></p><pre><code>Input: &quot;babad&quot;Output: &quot;bab&quot;Note: &quot;aba&quot; is also a valid answer.</code></pre><p><strong>Example 2:</strong></p><pre><code>Input: &quot;cbbd&quot;Output: &quot;bb&quot;</code></pre><p>题目要求我们找到给定字符串中的所有回文子串中最长子串。</p><h2 id="思路分析">思路分析</h2><p>这个题目和之前的<a href="https://theonegis.github.io/algorithm/LeetCode-Palindromic-Substrings/">LeetCode-Palindromic Substrings</a>题目的思路是一样的，<a href="https://leetcode.com/problems/palindromic-substrings/" target="_blank" rel="noopener">Palindromic Substrings</a>是找回文的个数。在这个过程中其实我们是找出了所有的回文子串，接下来我们统计一下每个回文的长度，选择出最长的那个就是本文的答案了（当然，在代码实现过程中统计最长子串不一定是找到了所有的子串之后再统计，可能是边寻找边统计）。所以，方法还是老方法，可以利用动态规划，也可以利用中心扩散法。</p><p>有不明白的地方可以参见我之前的博文《<a href="https://theonegis.github.io/algorithm/LeetCode-Palindromic-Substrings/">LeetCode-Palindromic Substrings</a>》，这里我只给出了使用中心扩散法进行求解的代码实现。</p><h2 id="c实现">C++实现</h2><div class="sourceCode" id="cb3"><pre class="sourceCode c++"><code class="sourceCode cpp"><span id="cb3-1"><a href="#cb3-1"></a><span class="kw">class</span> Solution {</span><span id="cb3-2"><a href="#cb3-2"></a><span class="kw">private</span>:</span><span id="cb3-3"><a href="#cb3-3"></a>    <span class="dt">int</span> longest = <span class="dv">0</span>;            <span class="co">// 记录最长子串的字符个数</span></span><span id="cb3-4"><a href="#cb3-4"></a>    string palindrome = <span class="st">&quot;&quot;</span>;     <span class="co">// 保存最长的子串</span></span><span id="cb3-5"><a href="#cb3-5"></a>    <span class="dt">void</span> extendPalindrome(<span class="at">const</span> string&amp; s, <span class="dt">int</span> left, <span class="dt">int</span> right) {</span><span id="cb3-6"><a href="#cb3-6"></a>        <span class="cf">while</span> ((left &gt;= <span class="dv">0</span>) &amp;&amp; (right &lt; s.size()) &amp;&amp; (s[left] == s[right])) {</span><span id="cb3-7"><a href="#cb3-7"></a>            --left;</span><span id="cb3-8"><a href="#cb3-8"></a>            ++right;</span><span id="cb3-9"><a href="#cb3-9"></a>        }</span><span id="cb3-10"><a href="#cb3-10"></a>        <span class="dt">int</span> count = right - left - <span class="dv">1</span>;</span><span id="cb3-11"><a href="#cb3-11"></a>        <span class="cf">if</span> (count &gt; longest) {</span><span id="cb3-12"><a href="#cb3-12"></a>            longest = count;</span><span id="cb3-13"><a href="#cb3-13"></a>            palindrome = s.substr(left + <span class="dv">1</span>, longest);</span><span id="cb3-14"><a href="#cb3-14"></a>        }</span><span id="cb3-15"><a href="#cb3-15"></a>    }</span><span id="cb3-16"><a href="#cb3-16"></a></span><span id="cb3-17"><a href="#cb3-17"></a><span class="kw">public</span>:</span><span id="cb3-18"><a href="#cb3-18"></a>    string longestPalindrome(string s) {</span><span id="cb3-19"><a href="#cb3-19"></a>        <span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; s.size(); ++i) {</span><span id="cb3-20"><a href="#cb3-20"></a>            extendPalindrome(s, i, i);</span><span id="cb3-21"><a href="#cb3-21"></a>            extendPalindrome(s, i, i + <span class="dv">1</span>);</span><span id="cb3-22"><a href="#cb3-22"></a>        }</span><span id="cb3-23"><a href="#cb3-23"></a>        <span class="cf">return</span> palindrome;</span><span id="cb3-24"><a href="#cb3-24"></a>    }</span><span id="cb3-25"><a href="#cb3-25"></a>};</span></code></pre></div><p>可以对比一下，和<a href="https://theonegis.github.io/algorithm/LeetCode-Palindromic-Substrings/">LeetCode-Palindromic Substrings</a>的答案是不是没多大变化？</p><h2 id="scala实现">Scala实现</h2><div class="sourceCode" id="cb4"><pre class="sourceCode scala"><code class="sourceCode scala"><span id="cb4-1"><a href="#cb4-1"></a><span class="kw">object</span> Solution {</span><span id="cb4-2"><a href="#cb4-2"></a>  <span class="kw">def</span> <span class="fu">longestPalindrome</span>(s: String): String = {</span><span id="cb4-3"><a href="#cb4-3"></a>    s.<span class="fu">length</span> <span class="kw">match</span> {</span><span id="cb4-4"><a href="#cb4-4"></a>      <span class="kw">case</span> <span class="dv">0</span> =&gt; s</span><span id="cb4-5"><a href="#cb4-5"></a>      <span class="kw">case</span> _ =&gt; {</span><span id="cb4-6"><a href="#cb4-6"></a>        <span class="kw">val</span> longest = (<span class="kw">for</span> {</span><span id="cb4-7"><a href="#cb4-7"></a>          i &lt;- s.<span class="fu">indices</span></span><span id="cb4-8"><a href="#cb4-8"></a>          j &lt;- List(i, i + <span class="dv">1</span>)</span><span id="cb4-9"><a href="#cb4-9"></a>          k &lt;- (i to <span class="dv">0</span> by <span class="dv">-1</span>).<span class="fu">zip</span>(j until s.<span class="fu">length</span>).<span class="fu">takeWhile</span>(p =&gt; <span class="fu">s</span>(p._<span class="dv">1</span>) == <span class="fu">s</span>(p._<span class="dv">2</span>))</span><span id="cb4-10"><a href="#cb4-10"></a>        } <span class="kw">yield</span> (k._<span class="dv">1</span>, k._<span class="dv">2</span>)).<span class="fu">maxBy</span>(p =&gt; p._<span class="dv">2</span> - p._<span class="dv">1</span>)</span><span id="cb4-11"><a href="#cb4-11"></a>        s.<span class="fu">substring</span>(longest._<span class="dv">1</span>, longest._<span class="dv">2</span> + <span class="dv">1</span>)</span><span id="cb4-12"><a href="#cb4-12"></a>      }</span><span id="cb4-13"><a href="#cb4-13"></a>    }</span><span id="cb4-14"><a href="#cb4-14"></a>  }</span><span id="cb4-15"><a href="#cb4-15"></a>}</span></code></pre></div><p>这里需要注意的是：</p><ol type="1"><li><p>需要对于空字符串的特殊处理（这里使用的是<code>match</code>匹配，当然也可以使用<code>if...else</code>条件语句）</p></li><li><p>我们使用<code>yield</code>每次生成回文子串的左右指针，然后再使用<code>maxBy</code>得到最长子串对应的左右指针。</p></li><li><p><code>takeWhile</code>函数对集合进行遍历过程中当条件不满足的时候会立即停止判断，返回的是最后那个满足的元素。（<code>filter</code>函数会返回集合中所有满足条件的元素）</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;版权声明：本文为博主原创文章，转载请注明原文出处！&lt;/p&gt;
&lt;p&gt;写作时间：2019-02-10 00:04:34&lt;/p&gt;
&lt;h1 id=&quot;leetcode-longest-palindromic-substring&quot;&gt;LeetCode-Longest Palindromi
      
    
    </summary>
    
      <category term="算法" scheme="http://theonegis.github.io/categories/algorithm/"/>
    
    
      <category term="LeetCode" scheme="http://theonegis.github.io/tags/LeetCode/"/>
    
      <category term="回文" scheme="http://theonegis.github.io/tags/%E5%9B%9E%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>LeetCode-Palindromic Substrings</title>
    <link href="http://theonegis.github.io/algorithm/LeetCode-Palindromic-Substrings/"/>
    <id>http://theonegis.github.io/algorithm/LeetCode-Palindromic-Substrings/</id>
    <published>2019-02-07T02:54:47.000Z</published>
    <updated>2019-03-22T19:39:53.823Z</updated>
    
    <content type="html"><![CDATA[<h1 id="leetcode-palindromic-substrings">LeetCode-Palindromic Substrings</h1><h2 id="题目描述">题目描述</h2><p>这是第647道题目：<a href="https://leetcode.com/problems/palindromic-substrings/" target="_blank" rel="noopener">Palindromic Substrings</a></p><p>Given a string, your task is to count how many palindromic substrings in this string.</p><p>The substrings with different start indexes or end indexes are counted as different substrings even they consist of same characters.</p><p><strong>Example 1:</strong></p><pre><code>Input: &quot;abc&quot;Output: 3Explanation: Three palindromic strings: &quot;a&quot;, &quot;b&quot;, &quot;c&quot;.</code></pre><p><strong>Example 2:</strong></p><pre><code>Input: &quot;aaa&quot;Output: 6Explanation: Six palindromic strings: &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;aa&quot;, &quot;aa&quot;, &quot;aaa&quot;.</code></pre><p>题目要求是需要计算出给定字符串中所有回文子串的个数（单个字符也算一个回文子串，不同索引位置的相同内容的回文子串也算不同的回文）</p><h2 id="思路分析">思路分析</h2><p>有两种思路：一种是采用动态规划的方法；另一种是采用中心扩散的方法。</p><ol type="1"><li><p>动态规划</p><p>如果用<code>dp[i][j]</code>表示从第<code>i</code>个字符到第<code>j</code>个字符是不是回文子串，<code>s</code>表示给定字符串，则有</p><p><code>dp[i][j]</code>= (<code>s[i]</code> == <code>s[j]</code>) &amp;&amp; (<code>i</code> - <code>j</code> &lt; 2) （这里表示的是子串是一个字符，两个字符的情形）</p><p><code>dp[i][j]</code>= (<code>s[i]</code> == <code>s[j]</code>) &amp;&amp; (<code>dp[i + 1][j -1]</code> ) （这里表示的是除了前面两种情形之外的情形）</p><p>注：三个字符串的情形既可以归类到第一种情况（如果归类到第一种情况，则条件需要变为<code>i</code> - <code>j</code> &lt; 3），也可以归类到第二种情形</p></li><li><p>中心扩散</p><p>扩散法假定一个中心，然后采用左右两个指针同时向两边走来判断是不是回文。</p><p>注：中心扩散法需要区分回文子串中的字符个数是奇数和偶数两种情况。</p></li></ol><h2 id="c实现">C++实现</h2><ol type="1"><li><p>动态规划</p><div class="sourceCode" id="cb3"><pre class="sourceCode c++"><code class="sourceCode cpp"><span id="cb3-1"><a href="#cb3-1"></a><span class="kw">class</span> Solution {</span><span id="cb3-2"><a href="#cb3-2"></a><span class="kw">public</span>:</span><span id="cb3-3"><a href="#cb3-3"></a>    <span class="dt">int</span> countSubstrings(string s) {</span><span id="cb3-4"><a href="#cb3-4"></a>        <span class="at">const</span> <span class="dt">int</span> N = <span class="kw">static_cast</span>&lt;<span class="dt">int</span>&gt;(s.size());   <span class="co">// 如果不强转就会超时，好奇怪</span></span><span id="cb3-5"><a href="#cb3-5"></a>        <span class="dt">int</span> count = <span class="dv">0</span>;</span><span id="cb3-6"><a href="#cb3-6"></a>        <span class="co">// 下面这一行换成原生数组也是可以的int dp[N][N]</span></span><span id="cb3-7"><a href="#cb3-7"></a>        vector&lt;vector&lt;<span class="dt">bool</span>&gt;&gt; dp(N, vector&lt;<span class="dt">bool</span>&gt;(N));</span><span id="cb3-8"><a href="#cb3-8"></a>        <span class="co">// 从后面遍历是为了让求dp[i][j]的时候dp[i + 1][j - 1]是已经计算过的</span></span><span id="cb3-9"><a href="#cb3-9"></a>        <span class="cf">for</span> (<span class="kw">auto</span> i = N - <span class="dv">1</span>; i &gt;= <span class="dv">0</span>; --i) {</span><span id="cb3-10"><a href="#cb3-10"></a>            <span class="cf">for</span> (<span class="kw">auto</span> j = i; j &lt; N; ++j) {</span><span id="cb3-11"><a href="#cb3-11"></a>                <span class="co">// (j - i &lt; 2)包含了两种情况，使得dp[i + 1][j - 1]可以包含剩下的所有情况</span></span><span id="cb3-12"><a href="#cb3-12"></a>                dp[i][j] = (s[i] == s[j]) &amp;&amp; ((j - i &lt; <span class="dv">2</span>) || dp[i + <span class="dv">1</span>][j - <span class="dv">1</span>]);</span><span id="cb3-13"><a href="#cb3-13"></a>                <span class="cf">if</span> (dp[i][j]) count++;</span><span id="cb3-14"><a href="#cb3-14"></a>            }</span><span id="cb3-15"><a href="#cb3-15"></a>        }</span><span id="cb3-16"><a href="#cb3-16"></a></span><span id="cb3-17"><a href="#cb3-17"></a>        <span class="cf">return</span> count;</span><span id="cb3-18"><a href="#cb3-18"></a>    }</span><span id="cb3-19"><a href="#cb3-19"></a>};</span></code></pre></div><p>在使用C++实现的时候，我发现一些有意思的现象：</p><ol type="1"><li>在第四行<code>s.size()</code>的返回类型本来是<code>size_t</code>，但是如果直接使用<code>size_t</code>的话，运行直接超时。我强制转换为<code>int</code>以后就可以通过测试。有童鞋能帮我解答一下疑惑吗？🙏</li><li>用于存储<code>dp</code>的使用动态数组<code>vector</code>是一般都会想到的，但是我看到一些提交中也有直接使用C++原生数组的。我就奇怪了，C++原生数组的话需要使用<code>new</code>操作符去动态申请，为什么直接使用也可以通过编译呢？我后来查了一些资料，原来C99标准中支持了原生动态数组（标准中称之为变成数组variable length array）。但是C++标准中这个特性是可选的，就是说可能有的编译器支持这样写，而有的编译器不行。不过，原生数组相对<code>vector</code>容器，效率会更高一些。如果你的编译器支持，大胆地使用吧！</li></ol></li><li><p>中心扩散</p><div class="sourceCode" id="cb4"><pre class="sourceCode c++"><code class="sourceCode cpp"><span id="cb4-1"><a href="#cb4-1"></a><span class="kw">class</span> Solution {</span><span id="cb4-2"><a href="#cb4-2"></a><span class="kw">private</span>:</span><span id="cb4-3"><a href="#cb4-3"></a>    <span class="dt">int</span> count = <span class="dv">0</span>;</span><span id="cb4-4"><a href="#cb4-4"></a>    <span class="dt">void</span> extendPalindrome(<span class="at">const</span> string&amp; s, <span class="dt">int</span> left, <span class="dt">int</span> right) {</span><span id="cb4-5"><a href="#cb4-5"></a>        <span class="cf">while</span> ((left &gt;= <span class="dv">0</span>) &amp;&amp; (right &lt; s.size()) &amp;&amp; (s[left] == s[right])) {</span><span id="cb4-6"><a href="#cb4-6"></a>            --left;</span><span id="cb4-7"><a href="#cb4-7"></a>            ++right;</span><span id="cb4-8"><a href="#cb4-8"></a>            ++count;</span><span id="cb4-9"><a href="#cb4-9"></a>        }</span><span id="cb4-10"><a href="#cb4-10"></a>    }</span><span id="cb4-11"><a href="#cb4-11"></a></span><span id="cb4-12"><a href="#cb4-12"></a><span class="kw">public</span>:</span><span id="cb4-13"><a href="#cb4-13"></a>    <span class="dt">int</span> countSubstrings(string s) {</span><span id="cb4-14"><a href="#cb4-14"></a>        <span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; s.size(); ++i) {</span><span id="cb4-15"><a href="#cb4-15"></a>            extendPalindrome(s, i, i);      <span class="co">// 对于奇数个字符的回文</span></span><span id="cb4-16"><a href="#cb4-16"></a>            extendPalindrome(s, i, i + <span class="dv">1</span>);  <span class="co">// 对于偶数个字符的回文</span></span><span id="cb4-17"><a href="#cb4-17"></a>        }</span><span id="cb4-18"><a href="#cb4-18"></a>        <span class="cf">return</span> count;</span><span id="cb4-19"><a href="#cb4-19"></a>    }</span><span id="cb4-20"><a href="#cb4-20"></a>};</span></code></pre></div></li></ol><h2 id="scala实现">Scala实现</h2><p>Scala的实现是在LeetCode上看到一个大神的答案，使用纯函数实现，写得很美妙，拿过来与大家分享！</p><div class="sourceCode" id="cb5"><pre class="sourceCode scala"><code class="sourceCode scala"><span id="cb5-1"><a href="#cb5-1"></a><span class="kw">object</span> Solution {</span><span id="cb5-2"><a href="#cb5-2"></a>    <span class="kw">def</span> <span class="fu">countSubstrings</span>(s: String): Int = {</span><span id="cb5-3"><a href="#cb5-3"></a>        (<span class="kw">for</span> {</span><span id="cb5-4"><a href="#cb5-4"></a>            i &lt;- <span class="dv">0</span> until s.<span class="fu">length</span></span><span id="cb5-5"><a href="#cb5-5"></a>            j &lt;- List(i, i + <span class="dv">1</span>)</span><span id="cb5-6"><a href="#cb5-6"></a>            _ &lt;- (i to <span class="dv">0</span> by <span class="dv">-1</span>).<span class="fu">zip</span>(j until s.<span class="fu">length</span>).<span class="fu">takeWhile</span>(p =&gt; <span class="fu">s</span>(p._<span class="dv">1</span>) == <span class="fu">s</span>(p._<span class="dv">2</span>))</span><span id="cb5-7"><a href="#cb5-7"></a>        } <span class="kw">yield</span> <span class="kw">true</span>).<span class="fu">length</span></span><span id="cb5-8"><a href="#cb5-8"></a>    }</span><span id="cb5-9"><a href="#cb5-9"></a>}</span></code></pre></div><p>这也是采用中心扩散法实现的。</p><p><code>for</code>循环中的<code>i</code>从左到右依次遍历给定字符串，<code>j</code>控制的是奇数个数的子串情况和偶数个数的子串情况，<code>for</code>循环中的第三个匿名变量其实相当于一个条件判断。整个<code>for</code>循环返回一个<code>vector</code>（里面都是<code>true</code>），最后统计这个<code>vector</code>个中包含元素的个数即可。</p><p>这里重点说一下<code>for</code>循环中的第三个匿名循环控制语句。<code>(i to 0 by -1).zip(j until s.length)</code>生成一个从中间向两边扩散的<code>List</code>（其实是<code>List</code>的子类<code>::</code>非空链表），这个<code>List</code>中的每个元素是一个<code>Tuple2</code>包含的是左指针<code>i</code>和右指针<code>j</code>。<code>takeWhile</code>方法是起到一个过滤作用，将左指针和右指针指向的值相等的这<code>Tuple2</code>返回（其实返回类型是<code>::</code>,只是里面只有一个元素）。如果左指针和右指针指向的值不相等，则返回<code>Nil（一个空的List）</code>。如果返回的是<code>Nil</code>的话，则不会生成一个<code>true</code>。这样子，其实第三个循环控制语句起到的是判断的作用。</p><p>注：</p><ol type="1"><li>Scala中的<code>Vector</code>类似于Java中的<code>ArrayList</code>，而Scala中的<code>List</code>类似于Java中的<code>LinkedList</code></li><li>Scala中的<code>List</code>有两个特殊的子类：<code>::</code>表示非空的<code>List</code>，<code>Nil</code>表示空的<code>List</code></li><li>函数<code>filter</code>和<code>takeWhile</code>都可以起到过滤的作用，<code>filter</code>会过滤出给定集合中所有满足条件的元素，而<code>takeWhile</code>只会返回第一个满足条件的元素。但是两者返回的都是集合，即使<code>takeWhile</code>返回的集合只有一个元素。</li></ol><p>感觉函数式编程是挺好玩的，只是现在水平有限，还玩不起来！继续加油！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;leetcode-palindromic-substrings&quot;&gt;LeetCode-Palindromic Substrings&lt;/h1&gt;
&lt;h2 id=&quot;题目描述&quot;&gt;题目描述&lt;/h2&gt;
&lt;p&gt;这是第647道题目：&lt;a href=&quot;https://leetcode
      
    
    </summary>
    
      <category term="算法" scheme="http://theonegis.github.io/categories/algorithm/"/>
    
    
      <category term="LeetCode" scheme="http://theonegis.github.io/tags/LeetCode/"/>
    
      <category term="动态规划" scheme="http://theonegis.github.io/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
      <category term="回文" scheme="http://theonegis.github.io/tags/%E5%9B%9E%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>LeetCode-Minimum Falling Path Sum</title>
    <link href="http://theonegis.github.io/algorithm/LeetCode-Minimum-Falling-Path-Sum/"/>
    <id>http://theonegis.github.io/algorithm/LeetCode-Minimum-Falling-Path-Sum/</id>
    <published>2019-02-04T13:13:56.000Z</published>
    <updated>2019-03-22T19:39:53.823Z</updated>
    
    <content type="html"><![CDATA[<h1 id="minimum-falling-path-sum">Minimum Falling Path Sum</h1><h2 id="题目描述">题目描述</h2><p>本题目链接：<a href="https://leetcode.com/problems/minimum-falling-path-sum/" target="_blank" rel="noopener">931. Minimum Falling Path Sum</a></p><p>Given a <strong>square</strong> array of integers <code>A</code>, we want the <strong>minimum</strong> sum of a <em>falling path</em>through <code>A</code>.</p><p>A falling path starts at any element in the first row, and chooses one element from each row. The next row’s choice must be in a column that is different from the previous row’s column by at most one.</p><p>题目的意思是在一个给定的二维方格中，从上往下走。列方向每次只走一步，行方向上最多只能跨越一个单元格。即就是只能向正下方，左下方，右下方行进。每个方格都有一个值，目标是走到最后一行的路径中包含的值之和最小。</p><h2 id="问题分析">问题分析</h2><p>还是使用动态规划，而动态规划的重中之重就是建立递推关系。</p><p>显然，对于第一行，我们选择最小的数进行开始；</p><p>然后，对于后面的，我们每次只要选择正下方，左下方，右下方中最小的数即可。</p><p>递推公式为：<code>dp[i][j] = dp[i-1][j] + min(A[i][j-1], A[i][j], A[i][j+1])</code>（注意对数组越界的处理）</p><h2 id="c实现">C++实现</h2><p>使用<code>A</code>当做<code>dp</code>数组，这样可以节省空间，但是我觉得对输入参数直接进行了修改，这样不是很好。</p><div class="sourceCode" id="cb1"><pre class="sourceCode c++"><code class="sourceCode cpp"><span id="cb1-1"><a href="#cb1-1"></a><span class="kw">class</span> Solution {</span><span id="cb1-2"><a href="#cb1-2"></a><span class="kw">public</span>:</span><span id="cb1-3"><a href="#cb1-3"></a>    <span class="dt">int</span> minFallingPathSum(vector&lt;vector&lt;<span class="dt">int</span>&gt;&gt; &amp;A) {</span><span id="cb1-4"><a href="#cb1-4"></a>        <span class="cf">for</span> (<span class="kw">auto</span> i = <span class="dv">1</span>; i &lt; A.size(); ++i) {</span><span id="cb1-5"><a href="#cb1-5"></a>            <span class="cf">for</span> (<span class="kw">auto</span> j = <span class="dv">0</span>; j &lt; A.size(); ++j) {</span><span id="cb1-6"><a href="#cb1-6"></a>                A[i][j] +=</span><span id="cb1-7"><a href="#cb1-7"></a>                        min({A[i - <span class="dv">1</span>][max(<span class="dv">0</span>, j - <span class="dv">1</span>)],</span><span id="cb1-8"><a href="#cb1-8"></a>                             A[i - <span class="dv">1</span>][j],</span><span id="cb1-9"><a href="#cb1-9"></a>                             A[i - <span class="dv">1</span>][min(<span class="kw">static_cast</span>&lt;<span class="dt">int</span>&gt;(A.size() - <span class="dv">1</span>), j + <span class="dv">1</span>)]});</span><span id="cb1-10"><a href="#cb1-10"></a>            }</span><span id="cb1-11"><a href="#cb1-11"></a></span><span id="cb1-12"><a href="#cb1-12"></a>        }</span><span id="cb1-13"><a href="#cb1-13"></a>        <span class="cf">return</span> *min_element(A.back().begin(), A.back().end());</span><span id="cb1-14"><a href="#cb1-14"></a>    }</span><span id="cb1-15"><a href="#cb1-15"></a>};</span></code></pre></div><h2 id="scala实现">Scala实现</h2><p>Scala版本的对输入参数<code>A</code>保持不变，但是这仍然不是纯函数的实现。如果有朋友有纯函数实现的方案，请不吝赐教！</p><div class="sourceCode" id="cb2"><pre class="sourceCode scala"><code class="sourceCode scala"><span id="cb2-1"><a href="#cb2-1"></a><span class="kw">object</span> Solution {</span><span id="cb2-2"><a href="#cb2-2"></a>  <span class="kw">def</span> <span class="fu">minFallingPathSum</span>(A: Array[Array[Int]]): Int = {</span><span id="cb2-3"><a href="#cb2-3"></a>    <span class="kw">val</span> dp = A.<span class="fu">clone</span>()</span><span id="cb2-4"><a href="#cb2-4"></a>    <span class="kw">for</span> (i &lt;- <span class="dv">1</span> until dp.<span class="fu">length</span>; j &lt;- dp.<span class="fu">indices</span>) {</span><span id="cb2-5"><a href="#cb2-5"></a>      <span class="fu">dp</span>(i)(j) += List(</span><span id="cb2-6"><a href="#cb2-6"></a>        <span class="fu">dp</span>(i - <span class="dv">1</span>)(math.<span class="fu">max</span>(<span class="dv">0</span>, j - <span class="dv">1</span>)),</span><span id="cb2-7"><a href="#cb2-7"></a>        <span class="fu">dp</span>(i - <span class="dv">1</span>)(j),</span><span id="cb2-8"><a href="#cb2-8"></a>        <span class="fu">dp</span>(i - <span class="dv">1</span>)(math.<span class="fu">min</span>(dp.<span class="fu">length</span> - <span class="dv">1</span>, j + <span class="dv">1</span>))).<span class="fu">min</span></span><span id="cb2-9"><a href="#cb2-9"></a>    }</span><span id="cb2-10"><a href="#cb2-10"></a>    dp.<span class="fu">last</span>.<span class="fu">min</span></span><span id="cb2-11"><a href="#cb2-11"></a>  }</span><span id="cb2-12"><a href="#cb2-12"></a>}</span></code></pre></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;minimum-falling-path-sum&quot;&gt;Minimum Falling Path Sum&lt;/h1&gt;
&lt;h2 id=&quot;题目描述&quot;&gt;题目描述&lt;/h2&gt;
&lt;p&gt;本题目链接：&lt;a href=&quot;https://leetcode.com/problems/mini
      
    
    </summary>
    
      <category term="算法" scheme="http://theonegis.github.io/categories/algorithm/"/>
    
    
      <category term="LeetCode" scheme="http://theonegis.github.io/tags/LeetCode/"/>
    
      <category term="动态规划" scheme="http://theonegis.github.io/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>LeetCode-Minimum Cost For Tickets</title>
    <link href="http://theonegis.github.io/algorithm/LeetCode-Minimum-Cost-For-Tickets/"/>
    <id>http://theonegis.github.io/algorithm/LeetCode-Minimum-Cost-For-Tickets/</id>
    <published>2019-02-04T04:41:11.000Z</published>
    <updated>2019-03-22T19:39:53.823Z</updated>
    
    <content type="html"><![CDATA[<h1 id="minimum-cost-for-tickets">Minimum Cost For Tickets</h1><h2 id="题目描述">题目描述</h2><p>LeetCode地址：<a href="https://leetcode.com/problems/minimum-cost-for-tickets/" target="_blank" rel="noopener">983. Minimum Cost For Tickets</a></p><p>In a country popular for train travel, you have planned some train travelling one year in advance. The days of the year that you will travel is given as an array <code>days</code>. Each day is an integer from <code>1</code> to <code>365</code>.</p><p>Train tickets are sold in 3 different ways:</p><ul><li>a 1-day pass is sold for <code>costs[0]</code> dollars;</li><li>a 7-day pass is sold for <code>costs[1]</code> dollars;</li><li>a 30-day pass is sold for <code>costs[2]</code> dollars.</li></ul><p>The passes allow that many days of consecutive travel. For example, if we get a 7-day pass on day 2, then we can travel for 7 days: day 2, 3, 4, 5, 6, 7, and 8.</p><p>Return the minimum number of dollars you need to travel every day in the given list of <code>days</code>.</p><p>days数组中存储的是该年中去旅游的日期（范围为1到365之间的数字），costs数组大小为3，存储的是1天，7天和30天火车票的价格。我们需要做一个方案选择合适的购票方案达到旅游days天最省钱的目的。</p><h2 id="算法描述">算法描述</h2><p>采用动态规划进行解决，假设现在是第days[i]天，我们在该天出行旅游需要选择买票方案，现在我们有三种方案：第一，购买一天的通行票，当天出行，花费就是第days[i-1]天的花费加上一天的通行票价；第二，购买七天的通行票，而七天的通行票可以在连续的七天之内使用，所以花费是第days[i-7]天的花费加上七天的通行票价（即从第days[i-8]天到days[i]天的花费都包含在这七天的通行票中）；第三，购买三十天的通行票，同理，花费是days[i-30]天加上三十天的通行票价。然后我们在这三种方案中选择最实惠的。最后，在实现代码中注意数组越界的问题。</p><p>使用dp[j]代表着我们旅行到i天为止需要的最少旅行价格，递推公式为：</p><ol type="1"><li>dp[j] = dp[j-1] （第j天不用旅行）</li><li>dp[j] = min(dp[j-1] + costs[0], dp[j-7] + costs[1], dp[j-30] + costs[2]) （第j天需要旅行）</li></ol><h2 id="c实现">C++实现</h2><div class="sourceCode" id="cb1"><pre class="sourceCode c++"><code class="sourceCode cpp"><span id="cb1-1"><a href="#cb1-1"></a><span class="kw">class</span> Solution {</span><span id="cb1-2"><a href="#cb1-2"></a><span class="kw">public</span>:</span><span id="cb1-3"><a href="#cb1-3"></a>    <span class="dt">int</span> mincostTickets(vector&lt;<span class="dt">int</span>&gt; &amp;days, vector&lt;<span class="dt">int</span>&gt; &amp;costs) {</span><span id="cb1-4"><a href="#cb1-4"></a>        <span class="cf">if</span> (days.size() == <span class="dv">0</span>) <span class="cf">return</span> <span class="dv">0</span>;</span><span id="cb1-5"><a href="#cb1-5"></a>        <span class="ot">assert</span>(costs.size() == <span class="dv">3</span>);</span><span id="cb1-6"><a href="#cb1-6"></a>        <span class="co">// dp[i]代表着我们旅行到i天需要的最少旅行价格, dp[0]为0，没实际含义</span></span><span id="cb1-7"><a href="#cb1-7"></a>        array&lt;<span class="dt">int</span>, <span class="dv">366</span>&gt; dp = {<span class="dv">0</span>};</span><span id="cb1-8"><a href="#cb1-8"></a>        <span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">1</span>; i &lt; dp.size(); ++i) {</span><span id="cb1-9"><a href="#cb1-9"></a>            <span class="co">// 如果这一天不旅行</span></span><span id="cb1-10"><a href="#cb1-10"></a>            <span class="cf">if</span> (find(days.begin(), days.end(), i) == days.end()) dp[i] = dp[i - <span class="dv">1</span>];</span><span id="cb1-11"><a href="#cb1-11"></a>            <span class="cf">else</span> {</span><span id="cb1-12"><a href="#cb1-12"></a>                dp[i] = min({</span><span id="cb1-13"><a href="#cb1-13"></a>                   dp[i - <span class="dv">1</span>] + costs[<span class="dv">0</span>],</span><span id="cb1-14"><a href="#cb1-14"></a>                   dp[max(<span class="dv">0</span>, i - <span class="dv">7</span>)] + costs[<span class="dv">1</span>],</span><span id="cb1-15"><a href="#cb1-15"></a>                   dp[max(<span class="dv">0</span>, i - <span class="dv">30</span>)] + costs[<span class="dv">2</span>]</span><span id="cb1-16"><a href="#cb1-16"></a>                });</span><span id="cb1-17"><a href="#cb1-17"></a>            }</span><span id="cb1-18"><a href="#cb1-18"></a>        }</span><span id="cb1-19"><a href="#cb1-19"></a>        <span class="cf">return</span> dp[<span class="dv">365</span>];</span><span id="cb1-20"><a href="#cb1-20"></a>    }</span><span id="cb1-21"><a href="#cb1-21"></a>};</span></code></pre></div><h2 id="scala实现">Scala实现</h2><p>注：如果有童鞋有纯函数的实现，希望分享出来！共享！</p><div class="sourceCode" id="cb2"><pre class="sourceCode scala"><code class="sourceCode scala"><span id="cb2-1"><a href="#cb2-1"></a><span class="kw">object</span> Solution {</span><span id="cb2-2"><a href="#cb2-2"></a>  <span class="kw">def</span> <span class="fu">mincostTickets</span>(days: Array[Int], costs: Array[Int]): Int = {</span><span id="cb2-3"><a href="#cb2-3"></a>    <span class="kw">if</span> (days.<span class="fu">length</span> == <span class="dv">0</span>) <span class="kw">return</span> <span class="dv">0</span></span><span id="cb2-4"><a href="#cb2-4"></a>    <span class="fu">assert</span>(costs.<span class="fu">length</span> == <span class="dv">3</span>)</span><span id="cb2-5"><a href="#cb2-5"></a>    <span class="kw">val</span> travels = days.<span class="fu">toSet</span></span><span id="cb2-6"><a href="#cb2-6"></a>    <span class="kw">val</span> dp = Array.<span class="fu">fill</span>[Int](<span class="dv">366</span>)(<span class="dv">0</span>)</span><span id="cb2-7"><a href="#cb2-7"></a></span><span id="cb2-8"><a href="#cb2-8"></a>    <span class="kw">for</span> (i &lt;- <span class="dv">1</span> until <span class="dv">366</span>) {</span><span id="cb2-9"><a href="#cb2-9"></a>      <span class="kw">if</span> (!travels.<span class="fu">contains</span>(i)) <span class="fu">dp</span>(i) = <span class="fu">dp</span>(i - <span class="dv">1</span>)</span><span id="cb2-10"><a href="#cb2-10"></a>      <span class="kw">else</span> <span class="fu">dp</span>(i) = List(</span><span id="cb2-11"><a href="#cb2-11"></a>        <span class="fu">dp</span>(i - <span class="dv">1</span>) + <span class="fu">costs</span>(<span class="dv">0</span>),</span><span id="cb2-12"><a href="#cb2-12"></a>        <span class="fu">dp</span>(math.<span class="fu">max</span>(<span class="dv">0</span>, i - <span class="dv">7</span>)) + <span class="fu">costs</span>(<span class="dv">1</span>),</span><span id="cb2-13"><a href="#cb2-13"></a>        <span class="fu">dp</span>(math.<span class="fu">max</span>(<span class="dv">0</span>, i - <span class="dv">30</span>)) + <span class="fu">costs</span>(<span class="dv">2</span>)</span><span id="cb2-14"><a href="#cb2-14"></a>      ).<span class="fu">min</span></span><span id="cb2-15"><a href="#cb2-15"></a>    }</span><span id="cb2-16"><a href="#cb2-16"></a></span><span id="cb2-17"><a href="#cb2-17"></a>    <span class="fu">dp</span>(<span class="dv">365</span>)</span><span id="cb2-18"><a href="#cb2-18"></a>  }</span><span id="cb2-19"><a href="#cb2-19"></a>}</span></code></pre></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;minimum-cost-for-tickets&quot;&gt;Minimum Cost For Tickets&lt;/h1&gt;
&lt;h2 id=&quot;题目描述&quot;&gt;题目描述&lt;/h2&gt;
&lt;p&gt;LeetCode地址：&lt;a href=&quot;https://leetcode.com/problems
      
    
    </summary>
    
      <category term="算法" scheme="http://theonegis.github.io/categories/algorithm/"/>
    
    
      <category term="LeetCode" scheme="http://theonegis.github.io/tags/LeetCode/"/>
    
      <category term="动态规划" scheme="http://theonegis.github.io/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>小波变换三之Haar变换</title>
    <link href="http://theonegis.github.io/math/%E5%B0%8F%E6%B3%A2%E5%8F%98%E6%8D%A2%E4%B8%89%E4%B9%8BHaar%E5%8F%98%E6%8D%A2/"/>
    <id>http://theonegis.github.io/math/小波变换三之Haar变换/</id>
    <published>2019-01-29T03:27:41.000Z</published>
    <updated>2019-03-22T19:39:53.832Z</updated>
    
    <content type="html"><![CDATA[<h1 id="小波变换三之haar变换">小波变换三之Haar变换</h1><h2 id="什么是基basis">什么是基（Basis）</h2><p>数学上有一个常用神秘专有名词“基”，那么什么是“基”呢？举个例子：在平面直角坐标系中的的一个点<span class="math inline">\((x, y)\)</span>的坐标可以表示为<span class="math inline">\(x\cdot{(1, 0)} + y\cdot{(0, 1)}\)</span>，这里的<span class="math inline">\((1, 0)\)</span>和<span class="math inline">\((0, 1)​\)</span>就是二维直角坐标系中的基，因为任意的点都可以通过这两个向量的加权进行表示。</p><p>其实，数学中很多定理或者法则都有这样的表示形式。比如：泰勒公式将任意一个可微函数表示为在该函数在某点的各阶导数的多项式的和；傅里叶级数任何周期函数都可以用正弦函数和余弦函数构成的无穷级数来表示。这些定理都是用无穷项的和来毕竟一个函数，而无穷项中的每一项都是一个系数乘以一个给定的函数，这些函数一起构成了所谓的“基”。</p><h2 id="haar小波基">Haar小波基</h2><p>其实，小波变换也是有“基”的。我们先直观来看，然后给出形式化的定义。</p><p>看例子，对于一个信号<span class="math inline">\(f = \{4, 6, 10, 12, 8, 6, 5, 5\}\)</span>，我们可以通过在《<a href="https://theonegis.github.io/math/%E5%B0%8F%E6%B3%A2%E5%8F%98%E6%8D%A2%E4%B8%80%E4%B9%8BHaar%E5%8F%98%E6%8D%A2/">小波变换一之Haar变换</a>》中讲述的方法计算其第一层的变换结果，我们也可以通过“基”辅助计算。</p><h3 id="第一层的基">第一层的基</h3><p>对于第一层的计算，Haar基是这样的：</p><p>对于近似表示的基，我们有：<span class="math display">\[\begin{matrix}V_1^1 = (\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}}, 0, 0, \cdots, 0) \\ V_2^1 = (0, 0, \frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}}, \cdots, 0) \\ V_{N/2}^1 = (0, 0, 0, 0, \frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}})\end{matrix}​\]</span></p><p>所以，变换以后的近似系数为<span class="math inline">\(a^1 = (fV_1^1, fV_2^1, \cdots, fV_{N/2}^1) = (5\sqrt{2}, 11\sqrt{2}, 7\sqrt{2}, 5\sqrt{2})​\)</span></p><p>类似的，对于细节表示的基，我们有：<span class="math display">\[\begin{matrix}W_1^1 = (\frac{1}{\sqrt{2}}, -\frac{1}{\sqrt{2}}, 0, 0, \cdots, 0) \\ W_2^1 = (0, 0, \frac{1}{\sqrt{2}}, -\frac{1}{\sqrt{2}}, \cdots, 0) \\ W_{N/2}^1 = (0, 0, 0, 0, \frac{1}{\sqrt{2}}, -\frac{1}{\sqrt{2}})\end{matrix}​\]</span></p><p>所以，变换以后的细节系数为<span class="math inline">\(d^1 = (fW_1^1, fW_2^1, \cdots, fW_{N/2}^1) = (-\sqrt{2}, -\sqrt{2}, -\sqrt{2}, 0)\)</span></p><h3 id="第二层的基">第二层的基</h3><p>对于第二层的计算（对<span class="math inline">\(a_1\)</span>进行小波分解），Haar基是这样的：</p><p>对于近似表示的基，我们有：<span class="math display">\[\begin{matrix}V_1^2 = (\frac{1}{2}, \frac{1}{2}, \frac{1}{2}, \frac{1}{2},0, 0, 0, 0, \cdots, 0, 0, 0, 0) \\ V_2^2 = (0, 0, 0, 0, \frac{1}{2}, \frac{1}{2}, \frac{1}{2}, \frac{1}{2}, \cdots, 0, 0, 0, 0) \\ V_{N/4}^2 = (0, 0, 0, 0, 0, 0, 0, 0,  \cdots, \frac{1}{2}, \frac{1}{2}, \frac{1}{2}, \frac{1}{2})\end{matrix}​\]</span></p><p>变换以后的近似系数为<span class="math inline">\(a^2 = (fV_1^2, fV_2^2, \cdots, fV_{N/4}^2) = (16, 12)\)</span></p><p>对于细节表示的基，我们有：<span class="math display">\[\begin{matrix}W_1^2 = (\frac{1}{2}, \frac{1}{2}, -\frac{1}{2}, -\frac{1}{2},0, 0, 0, 0, \cdots, 0, 0, 0, 0) \\ W_2^2 = (0, 0, 0, 0, \frac{1}{2}, \frac{1}{2}, -\frac{1}{2}, -\frac{1}{2}, \cdots, 0, 0, 0, 0) \\ W_{N/4}^2 = (0, 0, 0, 0, 0, 0, 0, 0,  \cdots, \frac{1}{2}, \frac{1}{2}, -\frac{1}{2}, -\frac{1}{2})\end{matrix}\]</span></p><p>变换以后的细节系数为<span class="math inline">\(d^1 = (fW_1^2, fW_2^2, \cdots, fW_{N/4}^2) = (-6, 2)​\)</span></p><p>后面，如果要继续再分解的话，我们可以找到类似上面的“基”做进一步分解。</p><p>可以看到Haar小波基都是正交的（与除了自己以外的其它基的內积为0），而且都经过了单位化（模为1）。</p><h2 id="母小波和父小波">母小波和父小波</h2><p>在小波变换中有两个重要的术语：母小波（mother wavelet）和父小波（father wavelet），而我们的小波基就是由父小波和母小波经过平移和缩放得到的。母小波也叫做小波函数（wavelet function），对应着细节系数的基，父小波也叫做缩放函数（scaling function），对应着近似系数的基。</p><p>Haar小波的母小波定义为<span class="math display">\[\psi(x) = \begin{cases}1, &amp; 0 \le x \lt \frac{1}{2} \\-1, &amp; \frac{1}{2}\le x \lt 1\\ 0, &amp; \mathrm{其它}\end{cases}​\]</span></p><p>Haar小波的父小波定义为<span class="math display">\[\phi(x) = \begin{cases}1, &amp; 0 \le x \le 1\\ 0, &amp; \mathrm{其它}\end{cases}\]</span></p><p>不止对于Haar小波，任何小波的基都是对其母小波和父小波缩放和平移后的集合。感兴趣的朋友可以在下面的网址中查看一下，如何对小波函数进行缩放和平移：<a href="http://demonstrations.wolfram.com/HaarFunctions/" target="_blank" rel="noopener">Haar Functions</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;小波变换三之haar变换&quot;&gt;小波变换三之Haar变换&lt;/h1&gt;
&lt;h2 id=&quot;什么是基basis&quot;&gt;什么是基（Basis）&lt;/h2&gt;
&lt;p&gt;数学上有一个常用神秘专有名词“基”，那么什么是“基”呢？举个例子：在平面直角坐标系中的的一个点&lt;span class=&quot;m
      
    
    </summary>
    
      <category term="数学" scheme="http://theonegis.github.io/categories/math/"/>
    
    
      <category term="小波变换" scheme="http://theonegis.github.io/tags/%E5%B0%8F%E6%B3%A2%E5%8F%98%E6%8D%A2/"/>
    
      <category term="Haar变换" scheme="http://theonegis.github.io/tags/Haar%E5%8F%98%E6%8D%A2/"/>
    
      <category term="Wavelet" scheme="http://theonegis.github.io/tags/Wavelet/"/>
    
  </entry>
  
  <entry>
    <title>C++中的万能引用和完美转发</title>
    <link href="http://theonegis.github.io/cxx/C-%E4%B8%AD%E7%9A%84%E4%B8%87%E8%83%BD%E5%BC%95%E7%94%A8%E5%92%8C%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91/"/>
    <id>http://theonegis.github.io/cxx/C-中的万能引用和完美转发/</id>
    <published>2019-01-20T09:38:11.000Z</published>
    <updated>2019-03-22T19:39:53.821Z</updated>
    
    <content type="html"><![CDATA[<h1 id="c中的万能引用和完美转发">C++中的万能引用和完美转发</h1><ol type="1"><li>阅读这篇博文需要了解C++中的左值（lvalue）和右值（rvalue）的概念，详情参见我的另外一篇博文：<a href="https://theonegis.github.io/cxx/C-%E7%A7%BB%E5%8A%A8%E8%AF%AD%E4%B9%89%E5%8F%8A%E6%8B%B7%E8%B4%9D%E4%BC%98%E5%8C%96/">C++移动语义及拷贝优化</a></li><li>万能引用和完美转发多涉及到模板的使用，如若不是自己写模板，则可不用关心</li></ol><h2 id="万能引用universal-reference">万能引用（Universal Reference）</h2><p>首先，我们来看一个例子：</p><div class="sourceCode" id="cb1"><pre class="sourceCode c++"><code class="sourceCode cpp"><span id="cb1-1"><a href="#cb1-1"></a><span class="pp">#include </span><span class="im">&lt;iostream&gt;</span></span><span id="cb1-2"><a href="#cb1-2"></a></span><span id="cb1-3"><a href="#cb1-3"></a><span class="kw">using</span> <span class="bu">std::</span>cout;</span><span id="cb1-4"><a href="#cb1-4"></a><span class="kw">using</span> <span class="bu">std::</span>endl;</span><span id="cb1-5"><a href="#cb1-5"></a></span><span id="cb1-6"><a href="#cb1-6"></a></span><span id="cb1-7"><a href="#cb1-7"></a><span class="kw">template</span>&lt;<span class="kw">typename</span> T&gt;</span><span id="cb1-8"><a href="#cb1-8"></a><span class="dt">void</span> func(T&amp; param) {</span><span id="cb1-9"><a href="#cb1-9"></a>    cout &lt;&lt; param &lt;&lt; endl;</span><span id="cb1-10"><a href="#cb1-10"></a>}</span><span id="cb1-11"><a href="#cb1-11"></a></span><span id="cb1-12"><a href="#cb1-12"></a></span><span id="cb1-13"><a href="#cb1-13"></a><span class="dt">int</span> main() {</span><span id="cb1-14"><a href="#cb1-14"></a>    <span class="dt">int</span> num = <span class="dv">2019</span>;</span><span id="cb1-15"><a href="#cb1-15"></a>    func(num);</span><span id="cb1-16"><a href="#cb1-16"></a>    <span class="cf">return</span> <span class="dv">0</span>;</span><span id="cb1-17"><a href="#cb1-17"></a>}</span></code></pre></div><p>这样例子的编译输出都没有什么问题，但是如果我们修改成下面的调用方式呢？</p><div class="sourceCode" id="cb2"><pre class="sourceCode c++"><code class="sourceCode cpp"><span id="cb2-1"><a href="#cb2-1"></a><span class="dt">int</span> main() {</span><span id="cb2-2"><a href="#cb2-2"></a>    func(<span class="dv">2019</span>);</span><span id="cb2-3"><a href="#cb2-3"></a>    <span class="cf">return</span> <span class="dv">0</span>;</span><span id="cb2-4"><a href="#cb2-4"></a>}</span></code></pre></div><p>则会得到一个大大的编译错误。因为上面的模板函数只能接受左值或者左值引用（左值一般是有名字的变量，可以取到地址的），我们当然可以重载一个接受右值的模板函数，如下也可以达到效果。</p><div class="sourceCode" id="cb3"><pre class="sourceCode c++"><code class="sourceCode cpp"><span id="cb3-1"><a href="#cb3-1"></a><span class="kw">template</span>&lt;<span class="kw">typename</span> T&gt;</span><span id="cb3-2"><a href="#cb3-2"></a><span class="dt">void</span> func(T&amp; param) {</span><span id="cb3-3"><a href="#cb3-3"></a>    cout &lt;&lt; <span class="st">&quot;传入的是左值&quot;</span> &lt;&lt; endl;</span><span id="cb3-4"><a href="#cb3-4"></a>}</span><span id="cb3-5"><a href="#cb3-5"></a><span class="kw">template</span>&lt;<span class="kw">typename</span> T&gt;</span><span id="cb3-6"><a href="#cb3-6"></a><span class="dt">void</span> func(T&amp;&amp; param) {</span><span id="cb3-7"><a href="#cb3-7"></a>    cout &lt;&lt; <span class="st">&quot;传入的是右值&quot;</span> &lt;&lt; endl;</span><span id="cb3-8"><a href="#cb3-8"></a>}</span><span id="cb3-9"><a href="#cb3-9"></a></span><span id="cb3-10"><a href="#cb3-10"></a></span><span id="cb3-11"><a href="#cb3-11"></a></span><span id="cb3-12"><a href="#cb3-12"></a><span class="dt">int</span> main() {</span><span id="cb3-13"><a href="#cb3-13"></a>    <span class="dt">int</span> num = <span class="dv">2019</span>;</span><span id="cb3-14"><a href="#cb3-14"></a>    func(num);</span><span id="cb3-15"><a href="#cb3-15"></a>    func(<span class="dv">2019</span>);</span><span id="cb3-16"><a href="#cb3-16"></a>    <span class="cf">return</span> <span class="dv">0</span>;</span><span id="cb3-17"><a href="#cb3-17"></a>}</span></code></pre></div><p>输出结果：</p><pre><code>传入的是左值传入的是右值</code></pre><p>第一次函数调用的是左值得版本，第二次函数调用的是右值版本。但是，有没有办法只写一个模板函数即可以接收左值又可以接收右值呢？</p><p>C++ 11中有万能引用（Universal Reference）的概念：使用<code>T&amp;&amp;</code>类型的形参既能绑定右值，又能绑定左值。</p><p>但是注意了：<strong>只有发生类型推导的时候，T&amp;&amp;才表示万能引用</strong>；否则，表示右值引用。</p><p>所以，上面的案例我们可以修改为：</p><div class="sourceCode" id="cb5"><pre class="sourceCode c++"><code class="sourceCode cpp"><span id="cb5-1"><a href="#cb5-1"></a><span class="kw">template</span>&lt;<span class="kw">typename</span> T&gt;</span><span id="cb5-2"><a href="#cb5-2"></a><span class="dt">void</span> func(T&amp;&amp; param) {</span><span id="cb5-3"><a href="#cb5-3"></a>    cout &lt;&lt; param &lt;&lt; endl;</span><span id="cb5-4"><a href="#cb5-4"></a>}</span><span id="cb5-5"><a href="#cb5-5"></a></span><span id="cb5-6"><a href="#cb5-6"></a></span><span id="cb5-7"><a href="#cb5-7"></a><span class="dt">int</span> main() {</span><span id="cb5-8"><a href="#cb5-8"></a>    <span class="dt">int</span> num = <span class="dv">2019</span>;</span><span id="cb5-9"><a href="#cb5-9"></a>    func(num);</span><span id="cb5-10"><a href="#cb5-10"></a>    func(<span class="dv">2019</span>);</span><span id="cb5-11"><a href="#cb5-11"></a>    <span class="cf">return</span> <span class="dv">0</span>;</span><span id="cb5-12"><a href="#cb5-12"></a>}</span></code></pre></div><h2 id="引用折叠universal-collapse">引用折叠（Universal Collapse）</h2><p>万能引用说完了，接着来聊引用折叠（Univers Collapse），因为完美转发（Perfect Forwarding）的概念涉及引用折叠。一个模板函数，根据定义的形参和传入的实参的类型，我们可以有下面四中组合：</p><ul><li>左值-左值 T&amp; &amp; # 函数定义的形参类型是左值引用，传入的实参是左值引用</li><li>左值-右值 T&amp; &amp;&amp; # 函数定义的形参类型是左值引用，传入的实参是右值引用</li><li>右值-左值 T&amp;&amp; &amp; # 函数定义的形参类型是右值引用，传入的实参是左值引用</li><li>右值-右值 T&amp;&amp; &amp;&amp; # 函数定义的形参类型是右值引用，传入的实参是右值引用</li></ul><p>但是C++中不允许对引用再进行引用，对于上述情况的处理有如下的规则：</p><p>所有的折叠引用最终都代表一个引用，要么是左值引用，要么是右值引用。规则是：<strong>如果任一引用为左值引用，则结果为左值引用。否则（即两个都是右值引用），结果为右值引用</strong>。</p><p>即就是前面三种情况代表的都是左值引用，而第四种代表的右值引用。</p><h2 id="完美转发perfect-forwarding">完美转发（Perfect Forwarding）</h2><p>下面接着说完美转发（Perfect Forwarding），首先，看一个例子：</p><div class="sourceCode" id="cb6"><pre class="sourceCode c++"><code class="sourceCode cpp"><span id="cb6-1"><a href="#cb6-1"></a><span class="pp">#include </span><span class="im">&lt;iostream&gt;</span></span><span id="cb6-2"><a href="#cb6-2"></a></span><span id="cb6-3"><a href="#cb6-3"></a><span class="kw">using</span> <span class="bu">std::</span>cout;</span><span id="cb6-4"><a href="#cb6-4"></a><span class="kw">using</span> <span class="bu">std::</span>endl;</span><span id="cb6-5"><a href="#cb6-5"></a></span><span id="cb6-6"><a href="#cb6-6"></a><span class="kw">template</span>&lt;<span class="kw">typename</span> T&gt;</span><span id="cb6-7"><a href="#cb6-7"></a><span class="dt">void</span> func(T&amp; param) {</span><span id="cb6-8"><a href="#cb6-8"></a>    cout &lt;&lt; <span class="st">&quot;传入的是左值&quot;</span> &lt;&lt; endl;</span><span id="cb6-9"><a href="#cb6-9"></a>}</span><span id="cb6-10"><a href="#cb6-10"></a><span class="kw">template</span>&lt;<span class="kw">typename</span> T&gt;</span><span id="cb6-11"><a href="#cb6-11"></a><span class="dt">void</span> func(T&amp;&amp; param) {</span><span id="cb6-12"><a href="#cb6-12"></a>    cout &lt;&lt; <span class="st">&quot;传入的是右值&quot;</span> &lt;&lt; endl;</span><span id="cb6-13"><a href="#cb6-13"></a>}</span><span id="cb6-14"><a href="#cb6-14"></a></span><span id="cb6-15"><a href="#cb6-15"></a></span><span id="cb6-16"><a href="#cb6-16"></a><span class="kw">template</span>&lt;<span class="kw">typename</span> T&gt;</span><span id="cb6-17"><a href="#cb6-17"></a><span class="dt">void</span> warp(T&amp;&amp; param) {</span><span id="cb6-18"><a href="#cb6-18"></a>    func(param);</span><span id="cb6-19"><a href="#cb6-19"></a>}</span><span id="cb6-20"><a href="#cb6-20"></a></span><span id="cb6-21"><a href="#cb6-21"></a></span><span id="cb6-22"><a href="#cb6-22"></a><span class="dt">int</span> main() {</span><span id="cb6-23"><a href="#cb6-23"></a>    <span class="dt">int</span> num = <span class="dv">2019</span>;</span><span id="cb6-24"><a href="#cb6-24"></a>    warp(num);</span><span id="cb6-25"><a href="#cb6-25"></a>    warp(<span class="dv">2019</span>);</span><span id="cb6-26"><a href="#cb6-26"></a>    <span class="cf">return</span> <span class="dv">0</span>;</span><span id="cb6-27"><a href="#cb6-27"></a>}</span></code></pre></div><p>猜一下，上面的输出结果是什么？</p><pre><code>传入的是左值传入的是左值</code></pre><p>是不是和我们预期的不一样，下面我们来分析一下原因：</p><p><code>warp()</code>函数本身的形参是一个万能引用，即可以接受左值又可以接受右值；第一个<code>warp()</code>函数调用实参是左值，所以，<code>warp()</code>函数中调用<code>func()</code>中传入的参数也应该是左值；第二个<code>warp()</code>函数调用实参是右值，根据上面所说的引用折叠规则，warp()<code>函数接收的参数类型是右值引用，那么为什么却调用了调用</code>func()的左值版本了呢？这是因为在<code>warp()</code>函数内部，左值引用类型变为了右值，因为参数有了名称，我们也通过变量名取得变量地址。</p><p>那么问题来了，怎么保持函数调用过程中，变量类型的不变呢？这就是我们所谓的“完美转发”技术，在C++11中通过<code>std::forward()</code>函数来实现。我们修改我们的<code>warp()</code>函数如下：</p><div class="sourceCode" id="cb8"><pre class="sourceCode c++"><code class="sourceCode cpp"><span id="cb8-1"><a href="#cb8-1"></a><span class="kw">template</span>&lt;<span class="kw">typename</span> T&gt;</span><span id="cb8-2"><a href="#cb8-2"></a><span class="dt">void</span> warp(T&amp;&amp; param) {</span><span id="cb8-3"><a href="#cb8-3"></a>    func(<span class="bu">std::</span>forward&lt;T&gt;(param));</span><span id="cb8-4"><a href="#cb8-4"></a>}</span></code></pre></div><p>则可以输出预期的结果。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;c中的万能引用和完美转发&quot;&gt;C++中的万能引用和完美转发&lt;/h1&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;阅读这篇博文需要了解C++中的左值（lvalue）和右值（rvalue）的概念，详情参见我的另外一篇博文：&lt;a href=&quot;https://theonegis.
      
    
    </summary>
    
      <category term="C++" scheme="http://theonegis.github.io/categories/cxx/"/>
    
    
      <category term="C++11" scheme="http://theonegis.github.io/tags/C-11/"/>
    
      <category term="完美转发" scheme="http://theonegis.github.io/tags/%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91/"/>
    
      <category term="万能引用" scheme="http://theonegis.github.io/tags/%E4%B8%87%E8%83%BD%E5%BC%95%E7%94%A8/"/>
    
      <category term="引用折叠" scheme="http://theonegis.github.io/tags/%E5%BC%95%E7%94%A8%E6%8A%98%E5%8F%A0/"/>
    
  </entry>
  
  <entry>
    <title>小波变换二之Haar变换</title>
    <link href="http://theonegis.github.io/math/%E5%B0%8F%E6%B3%A2%E5%8F%98%E6%8D%A2%E4%BA%8C%E4%B9%8BHaar%E5%8F%98%E6%8D%A2/"/>
    <id>http://theonegis.github.io/math/小波变换二之Haar变换/</id>
    <published>2019-01-17T06:45:55.000Z</published>
    <updated>2019-03-22T19:39:53.832Z</updated>
    
    <content type="html"><![CDATA[<h1 id="haar变换">Haar变换</h1><p>这是小波变换的第二篇，我们继续谈Haar变换。在第一篇中，我们介绍了一位情况下的Haar变换，这篇博文中主要介绍二维Haar变换。最后，通过一个图像压缩的案例说明二维Haar变换的应用。</p><h2 id="原理说明">原理说明</h2><p>给定一个二维信号，我们这里假设是一个<span class="math inline">\(4\times4\)</span>的图片，</p><p><span class="math inline">\(f=\begin{bmatrix}2&amp;1&amp;5&amp;6\\7&amp;6&amp;5&amp;8\\2&amp;1&amp;5&amp;5\\7&amp;7&amp;2&amp;10\end{bmatrix}\)</span></p><p>如何进行二维的哈尔变换呢？</p><p>步骤是这样的：（1）首先，沿着矩阵的每一行做一维的Haar变换；（2）然后，沿着矩阵的每一列做一维的哈尔变换；（3）对于每个低频分量矩阵（近似信息）重复步骤（1）和（2）直到完成指定的等级划分。下图给出了两级划分的示意图：</p><figure><img src="/images/math/Haar2D.png" alt=""><figcaption>二维Haar变换示意图</figcaption></figure><p>这里的A表示近似信息（approximation coefficients），H表示水平细节信息（horizontal detail coefficients），V表示垂直细节信息（vertical detail coefficients），D表示对角线细节信息（diagonal detail coefficients）。很多数学软件中是这样称呼的，了解了这个可以帮助我们快速上手软件进行实际操作。</p><p>行分解和列分解的顺序是可以互换的，保持一致即可。</p><p>明白了基本原理，下面我们来进行实际计算，对于<span class="math inline">\(f\)</span>，（如果不清楚如何做一维高频和低频分解，可参看博文<a href="https://blog.csdn.net/theonegis/article/details/86517377" target="_blank" rel="noopener">《小波变换一之Haar变换》</a>）</p><p>第一次行分解得到低频信息<span class="math inline">\(L=\begin{bmatrix}\frac{3}{\sqrt{2}}&amp;\frac{11}{\sqrt{2}}\\\frac{13}{\sqrt{2}}&amp;\frac{13}{\sqrt{2}}\\\frac{3}{\sqrt{2}}&amp;5\sqrt{2}\\7\sqrt{2}&amp;6\sqrt{2}\end{bmatrix}\)</span></p><p>第一次列分解得到高频信息<span class="math inline">\(H=\begin{bmatrix}\frac{1}{\sqrt{2}}&amp;-\frac{1}{\sqrt{2}}\\\frac{1}{\sqrt{2}}&amp;-\frac{3}{\sqrt{2}}\\\frac{1}{\sqrt{2}}&amp;0\\0&amp;-4\sqrt{2}\end{bmatrix}\)</span></p><p>对<span class="math inline">\(L\)</span>进行列高频分解得到<span class="math inline">\(A_1=\begin{bmatrix}8&amp;12\\8.5&amp;11\end{bmatrix}\)</span></p><p>对<span class="math inline">\(L\)</span>进行列低频分解得到<span class="math inline">\(H_1=\begin{bmatrix}-5&amp;-1\\-5.5&amp;-1\end{bmatrix}\)</span></p><p>对<span class="math inline">\(H\)</span>进行列高频分解得到<span class="math inline">\(V_1=\begin{bmatrix}1&amp;-2\\0.5&amp;-4\end{bmatrix}\)</span></p><p>对<span class="math inline">\(H\)</span>进行列低频分解得到<span class="math inline">\(D_1=\begin{bmatrix}0&amp;1\\0.5&amp;4\end{bmatrix}​\)</span></p><p>我们还可以对<span class="math inline">\(A_1​\)</span>继续进行二层分解，这里就不做演示了。</p><h2 id="实例演示">实例演示</h2><p>这里我们通过对一张图片做Haar变换，然后我们去掉其高频信息部分，实现对图像的压缩。</p><p>下面是进行了三次分解，然后分别过了到第一层的高频信息和第一层兼第二层的高频信息的效果！过滤掉第一层的高频信息，图像压缩为原来的四分之一，可以看到图像还是基本清晰的。过滤掉第二层和第二层的高频信息以后，可以看到图片稍微有点模糊了。</p><figure><img src="/images/math/Haar-Compress.jpg" alt=""><figcaption>Haar变换实现图像压缩</figcaption></figure><h2 id="matlab实现">MATLAB实现</h2><p>下面是使用MATLAB实现上面变换的代码，有兴趣的童鞋可以参考一下。</p><div class="sourceCode" id="cb1"><pre class="sourceCode matlab"><code class="sourceCode matlab"><span id="cb1-1"><a href="#cb1-1"></a><span class="va">clear</span><span class="op">,</span> <span class="va">clc</span><span class="op">;</span></span><span id="cb1-2"><a href="#cb1-2"></a></span><span id="cb1-3"><a href="#cb1-3"></a><span class="co">% 读取原始图像</span></span><span id="cb1-4"><a href="#cb1-4"></a><span class="va">X</span> <span class="op">=</span> <span class="va">rgb2gray</span>(<span class="va">imread</span>(<span class="ss">&#39;http://www.lenna.org/lena_std.tif&#39;</span>))<span class="op">;</span></span><span id="cb1-5"><a href="#cb1-5"></a><span class="co">% 进行小波分解</span></span><span id="cb1-6"><a href="#cb1-6"></a>[<span class="va">C</span><span class="op">,</span> <span class="va">S</span>] <span class="op">=</span> <span class="va">wavedec2</span>(<span class="va">X</span><span class="op">,</span> <span class="fl">3</span><span class="op">,</span> <span class="ss">&#39;haar&#39;</span>)<span class="op">;</span></span><span id="cb1-7"><a href="#cb1-7"></a></span><span id="cb1-8"><a href="#cb1-8"></a><span class="co">% 获得分解以后的低频近似信息</span></span><span id="cb1-9"><a href="#cb1-9"></a><span class="va">L</span> <span class="op">=</span> <span class="va">appcoef2</span>(<span class="va">C</span><span class="op">,</span> <span class="va">S</span><span class="op">,</span> <span class="ss">&#39;haar&#39;</span><span class="op">,</span> <span class="fl">3</span>)<span class="op">;</span></span><span id="cb1-10"><a href="#cb1-10"></a><span class="co">% 分别获得各层级的高频细节信息</span></span><span id="cb1-11"><a href="#cb1-11"></a>[<span class="va">H3</span><span class="op">,</span> <span class="va">V3</span><span class="op">,</span> <span class="va">D3</span>] <span class="op">=</span> <span class="va">detcoef2</span>(<span class="ss">&#39;all&#39;</span><span class="op">,</span> <span class="va">C</span><span class="op">,</span> <span class="va">S</span><span class="op">,</span> <span class="fl">3</span>)<span class="op">;</span></span><span id="cb1-12"><a href="#cb1-12"></a>[<span class="va">H2</span><span class="op">,</span> <span class="va">V2</span><span class="op">,</span> <span class="va">D2</span>] <span class="op">=</span> <span class="va">detcoef2</span>(<span class="ss">&#39;all&#39;</span><span class="op">,</span> <span class="va">C</span><span class="op">,</span> <span class="va">S</span><span class="op">,</span> <span class="fl">2</span>)<span class="op">;</span></span><span id="cb1-13"><a href="#cb1-13"></a>[<span class="va">H1</span><span class="op">,</span> <span class="va">V1</span><span class="op">,</span> <span class="va">D1</span>] <span class="op">=</span> <span class="va">detcoef2</span>(<span class="ss">&#39;all&#39;</span><span class="op">,</span> <span class="va">C</span><span class="op">,</span> <span class="va">S</span><span class="op">,</span> <span class="fl">1</span>)<span class="op">;</span></span><span id="cb1-14"><a href="#cb1-14"></a></span><span id="cb1-15"><a href="#cb1-15"></a><span class="co">% 去掉第一层的高频信息（替换成0），然后进行小波重建</span></span><span id="cb1-16"><a href="#cb1-16"></a><span class="co">% 注意这里乘以3是有HVD三种高频信息</span></span><span id="cb1-17"><a href="#cb1-17"></a><span class="va">D</span> <span class="op">=</span> [<span class="va">C</span>(<span class="fl">1</span><span class="op">:</span> <span class="kw">end</span> <span class="op">-</span> <span class="fl">3</span><span class="op">*</span><span class="va">size</span>(<span class="va">H1</span><span class="op">,</span> <span class="fl">1</span>)<span class="op">*</span><span class="va">size</span>(<span class="va">H1</span><span class="op">,</span> <span class="fl">2</span>))<span class="op">,</span> <span class="va">zeros</span>(<span class="fl">1</span><span class="op">,</span> <span class="fl">3</span><span class="op">*</span><span class="va">size</span>(<span class="va">H1</span><span class="op">,</span> <span class="fl">1</span>)<span class="op">*</span><span class="va">size</span>(<span class="va">H1</span><span class="op">,</span> <span class="fl">2</span>))]<span class="op">;</span></span><span id="cb1-18"><a href="#cb1-18"></a><span class="va">CD1</span> <span class="op">=</span> <span class="va">waverec2</span>(<span class="va">D</span><span class="op">,</span> <span class="va">S</span><span class="op">,</span> <span class="ss">&#39;haar&#39;</span>)<span class="op">;</span></span><span id="cb1-19"><a href="#cb1-19"></a><span class="co">% 去掉第一和第二层的高频信息，然后进行小波重建</span></span><span id="cb1-20"><a href="#cb1-20"></a><span class="va">D</span> <span class="op">=</span> [<span class="va">C</span>(<span class="fl">1</span><span class="op">:</span> <span class="kw">end</span> <span class="op">-</span> <span class="fl">3</span><span class="op">*</span><span class="va">size</span>(<span class="va">H1</span><span class="op">,</span> <span class="fl">1</span>)<span class="op">*</span><span class="va">size</span>(<span class="va">H1</span><span class="op">,</span> <span class="fl">2</span>) <span class="op">-</span> <span class="fl">3</span><span class="op">*</span><span class="va">size</span>(<span class="va">H2</span><span class="op">,</span> <span class="fl">1</span>)<span class="op">*</span><span class="va">size</span>(<span class="va">H2</span><span class="op">,</span> <span class="fl">2</span>))<span class="op">,</span> <span class="op">...</span></span><span id="cb1-21"><a href="#cb1-21"></a>    <span class="va">zeros</span>(<span class="fl">1</span><span class="op">,</span> <span class="fl">3</span><span class="op">*</span><span class="va">size</span>(<span class="va">H1</span><span class="op">,</span> <span class="fl">1</span>)<span class="op">*</span><span class="va">size</span>(<span class="va">H1</span><span class="op">,</span> <span class="fl">2</span>) <span class="op">+</span> <span class="fl">3</span><span class="op">*</span><span class="va">size</span>(<span class="va">H2</span><span class="op">,</span> <span class="fl">1</span>)<span class="op">*</span><span class="va">size</span>(<span class="va">H2</span><span class="op">,</span> <span class="fl">2</span>))]<span class="op">;</span></span><span id="cb1-22"><a href="#cb1-22"></a><span class="va">CD2</span> <span class="op">=</span> <span class="va">waverec2</span>(<span class="va">D</span><span class="op">,</span> <span class="va">S</span><span class="op">,</span> <span class="ss">&#39;haar&#39;</span>)<span class="op">;</span></span><span id="cb1-23"><a href="#cb1-23"></a></span><span id="cb1-24"><a href="#cb1-24"></a><span class="co">%按照分解层级将分解系数排列拼接为一副图像</span></span><span id="cb1-25"><a href="#cb1-25"></a><span class="va">DD1</span> <span class="op">=</span> [<span class="va">L</span><span class="op">,</span> <span class="va">H3</span><span class="op">;</span> <span class="va">V3</span><span class="op">,</span> <span class="va">D3</span>]<span class="op">;</span></span><span id="cb1-26"><a href="#cb1-26"></a><span class="va">DD2</span> <span class="op">=</span> [<span class="va">DD1</span><span class="op">,</span> <span class="va">H2</span><span class="op">;</span> <span class="va">V2</span><span class="op">,</span> <span class="va">D2</span>]<span class="op">;</span></span><span id="cb1-27"><a href="#cb1-27"></a><span class="va">DD3</span> <span class="op">=</span> [<span class="va">DD2</span><span class="op">,</span> <span class="va">H1</span><span class="op">;</span> <span class="va">V1</span><span class="op">,</span> <span class="va">D1</span>]<span class="op">;</span></span><span id="cb1-28"><a href="#cb1-28"></a><span class="co">% 结果显示</span></span><span id="cb1-29"><a href="#cb1-29"></a><span class="va">subplot</span>(<span class="fl">2</span><span class="op">,</span> <span class="fl">2</span><span class="op">,</span> <span class="fl">1</span>)<span class="op">,</span> <span class="va">imshow</span>(<span class="va">X</span><span class="op">,</span> [])<span class="op">,</span> <span class="va">title</span>(<span class="ss">&#39;原始图像&#39;</span>)<span class="op">;</span></span><span id="cb1-30"><a href="#cb1-30"></a><span class="va">subplot</span>(<span class="fl">2</span><span class="op">,</span> <span class="fl">2</span><span class="op">,</span> <span class="fl">2</span>)<span class="op">,</span> <span class="va">imshow</span>(<span class="va">DD3</span><span class="op">,</span> [])<span class="op">,</span> <span class="va">title</span>(<span class="ss">&#39;小波分解系数&#39;</span>)<span class="op">;</span></span><span id="cb1-31"><a href="#cb1-31"></a><span class="va">subplot</span>(<span class="fl">2</span><span class="op">,</span> <span class="fl">2</span><span class="op">,</span> <span class="fl">3</span>)<span class="op">,</span> <span class="va">imshow</span>(<span class="va">CD1</span><span class="op">,</span> [])<span class="op">,</span> <span class="va">title</span>(<span class="ss">&#39;压缩一（去掉第一层高频信息）&#39;</span>)<span class="op">;</span></span><span id="cb1-32"><a href="#cb1-32"></a><span class="va">subplot</span>(<span class="fl">2</span><span class="op">,</span> <span class="fl">2</span><span class="op">,</span> <span class="fl">4</span>)<span class="op">,</span> <span class="va">imshow</span>(<span class="va">CD2</span><span class="op">,</span> [])<span class="op">,</span> <span class="va">title</span>(<span class="ss">&#39;压缩二（去掉第二层高频信息）&#39;</span>)<span class="op">;</span></span></code></pre></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;haar变换&quot;&gt;Haar变换&lt;/h1&gt;
&lt;p&gt;这是小波变换的第二篇，我们继续谈Haar变换。在第一篇中，我们介绍了一位情况下的Haar变换，这篇博文中主要介绍二维Haar变换。最后，通过一个图像压缩的案例说明二维Haar变换的应用。&lt;/p&gt;
&lt;h2 id=&quot;原理说
      
    
    </summary>
    
      <category term="数学" scheme="http://theonegis.github.io/categories/math/"/>
    
    
      <category term="小波变换" scheme="http://theonegis.github.io/tags/%E5%B0%8F%E6%B3%A2%E5%8F%98%E6%8D%A2/"/>
    
      <category term="Haar变换" scheme="http://theonegis.github.io/tags/Haar%E5%8F%98%E6%8D%A2/"/>
    
      <category term="图像压缩" scheme="http://theonegis.github.io/tags/%E5%9B%BE%E5%83%8F%E5%8E%8B%E7%BC%A9/"/>
    
  </entry>
  
  <entry>
    <title>小波变换一之Haar变换</title>
    <link href="http://theonegis.github.io/math/%E5%B0%8F%E6%B3%A2%E5%8F%98%E6%8D%A2%E4%B8%80%E4%B9%8BHaar%E5%8F%98%E6%8D%A2/"/>
    <id>http://theonegis.github.io/math/小波变换一之Haar变换/</id>
    <published>2019-01-16T06:17:30.000Z</published>
    <updated>2019-03-22T19:39:53.832Z</updated>
    
    <content type="html"><![CDATA[<p>注：</p><ul><li>小波变换系列博文打算记录自己学习小波变换的心路历程，每篇博文尽量简短，宗旨是用最少的数学公式说明白如何使用小波变换</li><li>我的博客即将同步至腾讯云+社区，邀请大家一同入驻：<a href="https://cloud.tencent.com/developer/support-plan?invite_code=1roiym8d609t1" target="_blank" rel="noopener">https://cloud.tencent.com/developer/support-plan?invite_code=1roiym8d609t1</a></li></ul><h1 id="haar变换">Haar变换</h1><h2 id="案例一简单一维信号变换">案例一简单一维信号变换</h2><p>下面是一个一维信号（一组数）：<span class="math inline">\(f = \{2, 2, 2, 4, 4, 4\}\)</span></p><p>我对这个信号进行如下处理：</p><p><span class="math inline">\(a_m = \sqrt{2}\frac{f_{2m-1}+f_{2m}}{2} = \frac{f_{2m-1}+f_{2m}}{\sqrt{2}}\)</span>（相邻两个数相加，求平均，然后乘以<span class="math inline">\(\sqrt{2}\)</span>）</p><p><span class="math inline">\(d_m = \sqrt{2}\frac{f_{2m-1}-f_{2m}}{2} = \frac{f_{2m-1}-f_{2m}}{\sqrt{2}}\)</span>（相邻两个数相减，求平均，然后乘以<span class="math inline">\(\sqrt{2}\)</span>）</p><p>注：至于为什么要乘以<span class="math inline">\(\sqrt{2}\)</span>呢？我们这里先不解释，放到后面再说。</p><p>然后按照先<span class="math inline">\(a\)</span>后<span class="math inline">\(d\)</span>的顺序排列<span class="math inline">\({a_1,a_2,...,a_{N/2}, d_1, d_2, ..., d_{N/2}}\)</span>（<span class="math inline">\(N\)</span>是离散信号中的值的个数）</p><p>则，<span class="math inline">\(a = \{2\sqrt{2}, 3\sqrt{2}, 4\sqrt{2}\}\)</span>，<span class="math inline">\(d=\{0, -\sqrt{2}, 0\}\)</span></p><p>我们可以得到结果：<span class="math inline">\(tf = \{2\sqrt{2}, 3\sqrt{2}, 4\sqrt{2}, 0, -\sqrt{2}, 0\}\)</span></p><p>这就是传说中的Haar变换了……</p><p><span class="math inline">\(a\)</span>表示的是信号的趋势（trend），近似（approximation），是低频信息；而<span class="math inline">\(d\)</span>表示的是信号的细节（detail），是高频信息。</p><p>那么我们怎么变回去呢？我们对变换以后的信号进行如下处理：</p><p><span class="math inline">\(f_{2m-1} = \sqrt{2}\frac{a_m +d_m}{2} = \frac{a_m +d_m}{\sqrt{2}}\)</span>（第<span class="math inline">\(m\)</span>个<span class="math inline">\(a\)</span>和<span class="math inline">\(d\)</span>相加，求平均，然后乘以<span class="math inline">\(\sqrt{2}\)</span>）</p><p><span class="math inline">\(f_{2m} = \sqrt{2}\frac{a_m -d_m}{2} = \frac{a_m -d_m}{\sqrt{2}}\)</span> （第<span class="math inline">\(m\)</span>个<span class="math inline">\(a\)</span>和<span class="math inline">\(d\)</span>相减，求平均，然后乘以<span class="math inline">\(\sqrt{2}\)</span>）</p><p>我们可以得到结果<span class="math inline">\(if = \{2, 2, 2, 4, 4, 4\}\)</span></p><p>这样就是Haar变换的逆变换。</p><p>通过观察，我们可以发现：</p><ul><li><span class="math inline">\(d\)</span>中的数字绝大部分都很小（这是做信息压缩很重要的依据）</li><li>变换前后信号的能量保持不变，即<span class="math inline">\(\sum{f_i^2} = \sum{a_m^2} + \sum{d_i^2}\)</span>（有兴趣的同学可以算一下对于<span class="math inline">\(f\)</span>和<span class="math inline">\(tf\)</span>的能量都是60，刚好相等）</li></ul><h2 id="案例二多分辨率一维信号变换">案例二多分辨率一维信号变换</h2><p>我们可以按照上面的思路将信号对得到的低频信号（<span class="math inline">\(a\)</span>）一直一直划分下去，直到<span class="math inline">\(\mathrm{log}_2N\)</span>（离散信号的值的数目不是偶数的，可以在后面补0）</p><p>给定如下的一个信号：<span class="math inline">\(f(t) = 20x^2(1-x)^4\cos(12\pi x)\)</span></p><p>我们通过在[0, 1]之间取样1024个点可以得到信号的振幅，绘制出信号图像如下：</p><figure><img src="/images/math/原始信号.png" alt=""><figcaption>原始信号</figcaption></figure><p>我们可以通过案例一种描述的方法进行Haar变换，我们这里对<span class="math inline">\(f(t)\)</span>信号进行两次Haar变换，如下图所示：</p><figure><img src="/images/math/Haar多分辨率.png" alt=""><figcaption>Haar多分辨率分析</figcaption></figure><p>这是多分辨率分析（Multi-Resolution Analysis，MRA）以及图像压缩（JPEG2000编码）等的基础理念，这里现有一个大概理解，后面我们会继续谈到。</p><p>变换的结果如下（感兴趣的朋友可以使用Mathematica或者MATLAB是一样，这两个数学软件都提供了对Haar变换的直接支持）：</p><figure><img src="/images/math/Haar变换.png" alt=""><figcaption>Haar变换</figcaption></figure><p>好了，这一节先到这里，我们以后有时间慢慢聊！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;注：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;小波变换系列博文打算记录自己学习小波变换的心路历程，每篇博文尽量简短，宗旨是用最少的数学公式说明白如何使用小波变换&lt;/li&gt;
&lt;li&gt;我的博客即将同步至腾讯云+社区，邀请大家一同入驻：&lt;a href=&quot;https://cloud.tencen
      
    
    </summary>
    
      <category term="数学" scheme="http://theonegis.github.io/categories/math/"/>
    
    
      <category term="小波变换" scheme="http://theonegis.github.io/tags/%E5%B0%8F%E6%B3%A2%E5%8F%98%E6%8D%A2/"/>
    
      <category term="Haar变换" scheme="http://theonegis.github.io/tags/Haar%E5%8F%98%E6%8D%A2/"/>
    
  </entry>
  
  <entry>
    <title>变分法入门介绍</title>
    <link href="http://theonegis.github.io/math/%E5%8F%98%E5%88%86%E6%B3%95%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D/"/>
    <id>http://theonegis.github.io/math/变分法入门介绍/</id>
    <published>2019-01-09T08:18:23.000Z</published>
    <updated>2019-03-22T19:39:53.831Z</updated>
    
    <content type="html"><![CDATA[<h1 id="变分法入门介绍">变分法入门介绍</h1><p>读完这篇博文你可以了解变分的基本概念，以及使用变分法求解最简泛函的极值。本文没有严密的数学证明，只是感性地对变分法做一个初步了解。</p><h2 id="泛函和变分法">泛函和变分法</h2><p>给定两点<span class="math inline">\(A(x_0, y_0)\)</span>和<span class="math inline">\(B(x_1, y_1)\)</span>，求AB两点之间的最短距离。两点之间直线最短，这还用球吗？可是为什么是直线最短呢，而不是其它曲线？</p><p>设链接AB两点的曲线为<span class="math inline">\(f(x)\)</span>,则AB之间的距离可以表示为在区间<span class="math inline">\([x_0, x_1]\)</span>上求<span class="math inline">\(\Delta{S}=\sqrt{(\Delta{x})^2 + (\Delta{y})^2}\)</span>线段的累积长度（积分的思想）：</p><p><span class="math display">\[S=\int_{x_0}^{x_1}\sqrt{1+f&#39;(x)^2}dx\]</span></p><p>在这里该函数的变量是<span class="math inline">\(f\)</span>，即函数的变量为函数，我们需要求解出合适的<span class="math inline">\(f\)</span>使得<span class="math inline">\(S\)</span>最小。我们把这样的函数<span class="math inline">\(S\)</span>称为泛函数。</p><p>定义：<strong>泛函是以函数为变量的函数。</strong></p><p>那么什么是变分法呢？<strong>求泛函极值的方法称为变分法。</strong></p><h2 id="变分法求泛函极值">变分法求泛函极值</h2><h3 id="变分的定义">变分的定义</h3><p>下面给出变分的定义：对于任意定值<span class="math inline">\(x\in [x_0, x_1]\)</span>，可取函数<span class="math inline">\(y(x)\)</span>与另一可取函数<span class="math inline">\(y_0(x)\)</span>之差<span class="math inline">\(y(x) - y_0(x)\)</span>称为函数<span class="math inline">\(y(x)\)</span>在<span class="math inline">\(y_0(x)\)</span>处的变分或函数的变分，记做<span class="math inline">\(\delta{y}\)</span>，这时有<span class="math inline">\(\delta{y}=y(x) - y_0(x)=\epsilon\eta(x)\)</span>，<span class="math inline">\(\epsilon\)</span>是一个很小的数，<span class="math inline">\(\eta(x)\)</span>是<span class="math inline">\(x\)</span>的任意参数</p><p>对于泛函<span class="math inline">\(J[y(x)]\)</span>的增量<span class="math inline">\(\Delta{J}=J[y(x)+\delta{y}] - J[y(x)] = \delta{J} + \mathcal{o}(\delta{y})\)</span></p><p>泛函的增量<span class="math inline">\(\Delta{J}\)</span>与变分<span class="math inline">\(\delta{J}\)</span>之差是一个比一阶距离更高阶的无穷小，泛函的变分是泛函增量的线性主要部分。</p><p>变分的定义是不是跟微分很像（微分的定义<span class="math inline">\(\Delta{y}=A\Delta{x}+\mathcal{o}(\Delta{x})=dy+\mathcal{o}(\Delta(x)\)</span>，<span class="math inline">\(A\)</span>是该点的导数）。类比一下，我们在高等数学中学习到的函数极值的必要条件是函数导数等于0，而泛函极值的必要条件也是泛函的变分等于0。</p><p>所以有如下定理：若泛函<span class="math inline">\(J[y(x)]\)</span>在<span class="math inline">\(y=y(x)\)</span>上达到极值，则它在<span class="math inline">\(y=y(x)\)</span>上的变分<span class="math inline">\(\delta{J}\)</span>等于零。这就是变分原理。</p><h3 id="拉格朗日函数">拉格朗日函数</h3><p>设<span class="math inline">\(F(x, y(x), y&#39;(x))\)</span>是三个独立变量<span class="math inline">\(x\)</span>，<span class="math inline">\(y(x)\)</span>，<span class="math inline">\(y&#39;(x)\)</span>在区间<span class="math inline">\([x_0, x_1]\)</span>上的已知函数，且二阶连续可微，其中<span class="math inline">\(y(x)\)</span>和<span class="math inline">\(y&#39;(x)\)</span>是<span class="math inline">\(x\)</span>的未知函数，则泛函</p><p><span class="math display">\[J[y(x)]=\int_{x_0}^{x_1}F(x, y(x), y&#39;(x))dx\]</span></p><p>称为最简单的积分形泛函，简称最简泛函，被积函数<span class="math inline">\(F\)</span>称为拉格朗日函数。</p><p>对于拉格朗日函数，其泛函的变分为</p><p><span class="math display">\[\delta{J} = \int_{x_0}^{x_1}(F_y\delta{y} +F_{y&#39;}\delta{y&#39;})dx = \int_{x_0}^{x_1}(F_y\delta{y})dx + (F_{y&#39;}\delta_{y}|_{x_0}^{x_1} - \int_{x_0}^{x_1}(\delta_{y}\frac{d}{dx}F_{y&#39;}d{x})=\int_{x_0}^{x_1}(F_y-\frac{d}{dx}F_{y&#39;})\delta{y}dx\]</span></p><h3 id="欧拉方程">欧拉方程</h3><p>利用变分原理，使最简泛函<span class="math inline">\(J[y(x)]=\int_{x_0}^{x_1}F(x, y(x), y&#39;(x))dx\)</span>取得极值且满足固定边界条件<span class="math inline">\(y(x_0)=y_0\)</span>，<span class="math inline">\(y(x_1)=y_1\)</span>的极值曲线<span class="math inline">\(y=y(x)\)</span>应满足必要条件</p><p><span class="math display">\[F_y-\frac{d}{dx}F_{y&#39;}=0\]</span></p><p>式中<span class="math inline">\(F\)</span>是<span class="math inline">\(x, y, y&#39;\)</span>的已知函数并有二阶连续偏导数。上述必要条件中的方程叫做泛函的欧拉方程，也叫欧拉-拉格朗日方程。而<span class="math inline">\(F_y-\frac{d}{dx}F_{y&#39;}\)</span>称为<span class="math inline">\(F\)</span>关于<span class="math inline">\(y\)</span>的变分导（函）数。</p><h2 id="案例分析两点之间直线最短">案例分析–两点之间直线最短</h2><p>好的，我们利用欧拉方程来证明博文刚开始提出的两点之间直线最短的问题。</p><p>这里的<span class="math inline">\(F=\sqrt{1+f&#39;(x)^2}\)</span>，求得<span class="math inline">\(F_y=0\)</span>，<span class="math inline">\(F_{y&#39;}=\frac{y&#39;}{\sqrt{1+{y&#39;}^2}}\)</span>，再求得<span class="math inline">\(\frac{d}{dx}F_{y&#39;}=y&#39;&#39;(1+{y&#39;}^2)^{-\frac{3}{2}}\)</span></p><p>根据欧拉方程有<span class="math inline">\(-y&#39;&#39;(1+{y&#39;}^2)^{-\frac{3}{2}}=0\)</span>，则<span class="math inline">\(y&#39;&#39;=0 \Rightarrow y&#39;=C \Rightarrow y=C_1x + C_2\)</span></p><p>此时，我们就得到了这条曲线确实就是连接两点的直线。</p><h2 id="在mathematica中使用变分法">在Mathematica中使用变分法</h2><p>鉴于本人计算能力超级差，手动求导对我来说实在太痛苦了，我将上述的计算借助于Mathematica计算了一遍，下面是计算过程。不得不说Mathematica真的太强大了。</p><figure><img src="/images/math/Mathematica-Variational.png" alt=""><figcaption>Mathematica变分法</figcaption></figure><h2 id="参考文献">参考文献</h2><p>老大中. 变分法基础[M]. 北京: 国防工业出版社. 2004.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;变分法入门介绍&quot;&gt;变分法入门介绍&lt;/h1&gt;
&lt;p&gt;读完这篇博文你可以了解变分的基本概念，以及使用变分法求解最简泛函的极值。本文没有严密的数学证明，只是感性地对变分法做一个初步了解。&lt;/p&gt;
&lt;h2 id=&quot;泛函和变分法&quot;&gt;泛函和变分法&lt;/h2&gt;
&lt;p&gt;给定两点&lt;s
      
    
    </summary>
    
      <category term="数学" scheme="http://theonegis.github.io/categories/math/"/>
    
    
      <category term="变分法" scheme="http://theonegis.github.io/tags/%E5%8F%98%E5%88%86%E6%B3%95/"/>
    
      <category term="泛函" scheme="http://theonegis.github.io/tags/%E6%B3%9B%E5%87%BD/"/>
    
  </entry>
  
</feed>
